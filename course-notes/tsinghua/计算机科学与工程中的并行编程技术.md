# 1 导论
第一节课的内容：
1. MPI + X (CUDA/SASA/OpenMP/HIP 等并行编程框架) 
    MPI 执行进程级并行
    X 执行线程级并行
2. HPC is important.

# 2 MPI 并行程序设计入门
## 2.1 MPI 并行程序设计入门
### 并行编程简介
并行计算机可以
- 按照指令和数据的并行方式分类，分为 SIMD/SPMD/MIMD/MPMD 等
- 按照存储的组织方式分类，分为共享内存、分布式内存、分布式共享内存 (共享内存和分布式内存的结合)

并行编程模型包括：
- 数据并行：对不同的数据执行相同的操作
    OpenMP, OpenACC
    消息传递由编译器实现
    性能和效果依赖于编译器
    适用于 SIMD/SPMD，即单指令/单程序下的并行
    适用于共享内存
- 消息传递：对不同的数据执行不同的操作，用消息传递进行同步
    消息传递由程序员实现
    性能和效果依赖于程序员
    适用于 SIMD/SPMD/MIMD/MPMD 全部
    适用于分布式内存、分布式共享内存

### 并行算法
优化加速比 Speedup 定义为优化前后性能的提升比值，通常用执行时间的比值表示，即

$$
Speedup = \frac {T_{\text{before}}}{T_{\text{after}}}
$$

优化效率定义为优化加速比和理论最优加速比 $S$ 的比值，即

$$
E = \frac {Speedup}{S}
$$

对于一个既有串行成分又有并行成分的程序，它的理论最优加速比可以用 Amdahl定律计算，即

$$
S = \frac {1}{\frac {f_{\text{parellel}}}{P} + (1-f_{\text{parellel}})}
$$

其中 $P$ 表示并行的粒度，$f_{\text{parallel}}$ 表示程序中可并行的部分在串行执行时占用的计算时间的比率，或者可以粗略理解为并行程序所占的比率

Amdahl 定律指出，在并行粒度 $P$ 相同的情况下，尽可能多地并行化代码可以提高理论最优加速比

实践中，一般并行的粒度越小，越有可能开发更多的并行度，但并行的粒度越小，通信次数和通信量就相对增多，会带来更多的开销，这仍是一个 trade-off 问题

并行算法设计的一大重要原则就是增大计算时间相对于通信时间的比重，甚至**以计算换通信**
原因在于通信开销往往要远大于计算开销，因此需要尽可能降低通信次数 (为此并行粒度不能太小，以及需要尽可能合并可以合并的通信)，重叠计算和通信等等

### MPI 简介
MPI (Message Passing Interface) 是一种标准，不特指某个具体实现，它是一个消息传递编程模型，最终目的是服务于进程间通信这一目标

MPI 以独立于语言的形式定义其接口，对 Fortran, C, C++ 的绑定基于该定义实现，该定义不包含任何专用于某个操作系统、制造商、硬件的特性

MPI 程序的结构和其他程序的差异仅在于 MPI 环境，MPI 程序中，所有的 MPI 并行代码应该在 MPI 环境中，程序员需要在适合的地方初始化 MPI 环境和退出 MPI 环境

所有包含 MPI 的程序都需要 `#include` MPI 文件头，即 `#include <mpi.h>`

### 7 个基本 MPI 函数

```
MPI_INIT 进入 MPI 环境并初始化
MPI_FINALIZE 离开 MPI 环境
MPI_COMM_SIZE 返回当前通信域的进程数量
MPI_COMM_RANK 返回当前进程在通信域中的 ID
MPI_SEND 发送消息
MPI_RECV 接受消息
MPI_WTIME 计时函数
```

所有 MPI 名字都以 `MPI_` 前缀开头

MPI 接口的参数有三种类型：
- IN (输入)：接口的调用者传递给接口的参数，接口只能使用该参数，不得修改
- OUT (输出)：接口返回给其调用者的结果参数，该参数的初始值对接口没有意义
- INOUT (输入输出)：调用者将该参数传递给接口，接口修改该参数后返回给到用着，该参数的初始值和返回值都有意义

消息传递与消息接收：

```c
int MPI_Send(void* buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm)
int MPI_Recv(void* buf, int ocunt, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Status status)
```

前三个参数 (起始地址、消息长度、消息类型) 构成消息缓冲 (message buffer)，后三个参数 (接受/发送进程、消息标签、通信域) 构成消息信封 (message envelope)

MPI 的消息传递包括三个阶段：
- 消息装配：从缓冲区取数据，添加必要信息构造为消息
- 消息传递
- 消息拆卸：从消息中取出数据，存入缓冲区

三个阶段都需要类型匹配，装配时，缓冲区中变量类型需要和 `MPI_Send` 中指定的变量类型匹配，传递时，`MPI_Send` 和 `MPI_Recv` 指定的变量类型需要匹配，拆卸时，缓冲区变量类型需要和 `MPI_Recv` 指定的类型匹配

MPI 的消息类型/数据类型包括：
- 预定义数据类型：预定义数据类型会和语言的特定类型相对应
- 派生数据类型：用于处理包含了多种类型数据以及地址空间不连续的数据的消息

消息标签用于帮助接收者区分来自同一发送者的连续的消息，确保 `MPI_Send` 发出的消息由确定的 `MPI_Recv` 接受

接收者从 `MPI_Any_source` 接受 `MPI_Any_tag` 的消息时，消息状态中的信息可以用于确定消息的具体来源和标签

MPI 最基本的并行程序设计模式：主从模式、对等模式
基于这两个模式，可以设计任意复杂的 MPI 程序
