# 1 导论
第一节课的内容：
1. MPI + X (CUDA/SASA/OpenMP/HIP 等并行编程框架) 
    MPI 执行进程级并行
    X 执行线程级并行
2. HPC is important.

# 2 MPI 并行程序设计入门
## 并行编程简介
并行计算机可以
- 按照指令和数据的并行方式分类，分为 SIMD/SPMD/MIMD/MPMD 等
- 按照存储的组织方式分类，分为共享内存、分布式内存、分布式共享内存 (共享内存和分布式内存的结合)

并行编程模型包括：
- 数据并行：对不同的数据执行相同的操作
    OpenMP, OpenACC
    消息传递由编译器实现
    性能和效果依赖于编译器
    适用于 SIMD/SPMD，即单指令/单程序下的并行
    适用于共享内存
- 消息传递：对不同的数据执行不同的操作，用消息传递进行同步
    消息传递由程序员实现
    性能和效果依赖于程序员
    适用于 SIMD/SPMD/MIMD/MPMD 全部
    适用于分布式内存、分布式共享内存

## 并行算法
优化加速比 Speedup 定义为优化前后性能的提升比值，通常用执行时间的比值表示，即

$$
Speedup = \frac {T_{\text{before}}}{T_{\text{after}}}
$$

优化效率定义为优化加速比和理论最优加速比 $S$ 的比值，即

$$
E = \frac {Speedup}{S}
$$

对于一个既有串行成分又有并行成分的程序，它的理论最优加速比可以用 Amdahl定律计算，即

$$
S = \frac {1}{\frac {f_{\text{parellel}}}{P} + (1-f_{\text{parellel}})}
$$

其中 $P$ 表示并行的粒度，$f_{\text{parallel}}$ 表示程序中可并行的部分在串行执行时占用的计算时间的比率，或者可以粗略理解为并行程序所占的比率

Amdahl 定律指出，在并行粒度 $P$ 相同的情况下，尽可能多地并行化代码可以提高理论最优加速比

实践中，一般并行的粒度越小，越有可能开发更多的并行度，但并行的粒度越小，通信次数和通信量就相对增多，会带来更多的开销，这仍是一个 trade-off 问题

并行算法设计的一大重要原则就是增大计算时间相对于通信时间的比重，甚至**以计算换通信**
原因在于通信开销往往要远大于计算开销，因此需要尽可能降低通信次数 (为此并行粒度不能太小，以及需要尽可能合并可以合并的通信)，重叠计算和通信等等

## MPI 简介
MPI (Message Passing Interface) 是一种标准，不特指某个具体实现，它是一个消息传递编程模型，最终目的是服务于进程间通信这一目标

MPI 以独立于语言的形式定义其接口，对 Fortran, C, C++ 的绑定基于该定义实现，该定义不包含任何专用于某个操作系统、制造商、硬件的特性

MPI 程序的结构和其他程序的差异仅在于 MPI 环境，MPI 程序中，所有的 MPI 并行代码应该在 MPI 环境中，程序员需要在适合的地方初始化 MPI 环境和退出 MPI 环境

所有包含 MPI 的程序都需要 `#include` MPI 文件头，即 `#include <mpi.h>`

## 7 个基本 MPI 函数

```
MPI_INIT 进入 MPI 环境并初始化
MPI_FINALIZE 离开 MPI 环境
MPI_COMM_SIZE 返回当前通信域的进程数量
MPI_COMM_RANK 返回当前进程在通信域中的 ID
MPI_SEND 发送消息
MPI_RECV 接受消息
MPI_WTIME 计时函数
```

所有 MPI 名字都以 `MPI_` 前缀开头

MPI 接口的参数有三种类型：
- IN (输入)：接口的调用者传递给接口的参数，接口只能使用该参数，不得修改
- OUT (输出)：接口返回给其调用者的结果参数，该参数的初始值对接口没有意义
- INOUT (输入输出)：调用者将该参数传递给接口，接口修改该参数后返回给到用着，该参数的初始值和返回值都有意义

消息传递与消息接收：

```c
int MPI_Send(void* buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm)
int MPI_Recv(void* buf, int ocunt, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Status status)
```

前三个参数 (起始地址、消息长度、消息类型) 构成**消息缓冲** (message buffer)，后三个参数 (接受/发送进程、消息标签、通信域) 构成**消息信封** (message envelope)

MPI 的消息传递包括三个阶段：
- 消息装配：从缓冲区取数据，添加必要信息构造为消息
- 消息传递
- 消息拆卸：从消息中取出数据，存入缓冲区

三个阶段都需要类型匹配，装配时，缓冲区中变量类型需要和 `MPI_Send` 中指定的变量类型匹配，传递时，`MPI_Send` 和 `MPI_Recv` 指定的变量类型需要匹配，拆卸时，缓冲区变量类型需要和 `MPI_Recv` 指定的类型匹配

MPI 的消息类型/数据类型包括：
- 预定义数据类型：预定义数据类型会和语言的特定类型相对应
- 派生数据类型：用于处理包含了多种类型数据以及地址空间不连续的数据的消息

消息标签用于帮助接收者区分来自同一发送者的连续的消息，确保 `MPI_Send` 发出的消息由确定的 `MPI_Recv` 接受

接收者从 `MPI_Any_source` 接受 `MPI_Any_tag` 的消息时，消息状态中的信息可以用于确定消息的具体来源和标签

MPI 最基本的并行程序设计模式：主从模式、对等模式
基于这两个模式，可以设计任意复杂的 MPI 程序

# 3 MPI 进阶与深入
## MPI 的组通信
MPI 的通信：
- 点对点通信
- 组通信 (Collective Communications): 一个进程组中的所有进程都参加的全局通信操作

广播 `MPI_BCAST`：一个进程将相同的消息发送给通信域内所有其他进程
`MPI_BCAST` 的调用对于发送进程是发送消息，对于接受进程是接受消息，其他的组通信函数也是同理

收集 `MPI_GATHER`：一个进程从通信域内所有其他进程 (包括自己) 接受消息
收到的消息按照进程标识 rank 进行拼接，然后放入接受进程的缓冲区
`MPI_GATHER` 只能从每个进程收集同样多的数据，`MPI_GATHERV` 用于从不同进程收集不同大小的数据，`MPI_GATHERV` 还允许数据放在接受进程缓冲区的指定位置

散播 `MPI_SCATTER`: 执行和 GATHER 相反的操作，一个进程向其他进程发送不同的消息
SCATTERV 执行和 GATHERV 相反的操作

全局收集 `MPI_Allgather` : 相当于每个进程都执行一次 `MPI_GATHER` ，每个进程拿到所有进程的数据

全局交换 `MPI_Alltoall` : 相当于每个进程执行一次 `MPI_Scatter`

MPI 提供归约和扫描两种计算
归约 `MPI_Reduce`
组规约 `MPI_Allreduce` : 组内每个进程都执行一次归约操作，即每个进程都会有归约结果

扫描 `MPI_Scan` : 可以看作一种特殊的归约，每个进程都仅对排在它前面的进程执行归约操作

所有的MPI组通信操作都具有如下的特点:
- 通信域中的所有进程必须调用组通信函数。如果只有通信域中的一部分成员调用了组通信函数而其它没有调用，则是错误的。
- MPI_Barrier 以外，每个组通信函数使用类似于点对点通信中的标准、阻塞的通信模式。也就是说，一个进程一旦结束了它所参与的组操作就从组函数中返回，但是并不保证其它进程执行该组函数已经完成。
- 一个组通信操作是不是同步操作取决于实现。MPI要求用户负责保证他的代码无论实现是否同步都必须是正确的

通信模式：
标准通信模式
对要发送的数据是否进行缓存由 MPI 决定

缓存通信模式
用户控制缓存区，用户保证发送消息前一定有缓存区可用

同步通信模式
通信模式的开始不依赖于接受进程相应的接受操作是否已经开始，但同步发送必须等到相应的接受进程开始才可以正确返回

就绪通信模式
只有当接收进程的接收操作已经启动时，才可以在发送进程启动发送操作

## 非阻塞通信 MPI
阻塞通信：调用返回结果之前，当前进程悬挂
非阻塞通信：不等待返回结果

标准非阻塞发送 `MPI_ISEND`：其调用的返回仅意味着该消息可以被发送，而不是成功发送
标准非阻塞接受 `MPI_IRECV`：其调用的返回仅意味着符合要求的消息可以被接受，而不是接受到了消息

参数 `request` 为非阻塞通信对象，描述了通信状态，`MPI_WAIT` 以 `request` 为参数，直到它对应的通信完成才返回，同时释放 `request`

## MPI 并行程序设计的两种基本模式
对等模式、主从模式

对等模式实例：jacobi 算法
局部性较好的算法都可以取得较高的并行性
halo 区：将数据按块分割 (给每个进程)，各块之内可以独立并行计算，各块之间相邻的元素则需要通信取得，因此各块需要额外分配一个 halo 区存储从邻居块通信得来的数据

在迭代之前，每个进程都需要从相邻进程取得数据块，同时也需要向相邻进程提供数据块
MPI 提供了捆绑发送和接受操作 `MPI_Sendrecv` ，可以在一条MPI语句中同时实现向其它进程的数据发送和从其它进程接收数据操作
`MPI_SENDRECV` 可以有效避免单独书写发送和接受操作时由于次序错误导致的死锁，因为系统会优化 `MPI_SENDRECV` 内的通信次序


对于左侧和右侧的边界块，不容易将各自的发送和接收操作合并到一个调用之中，因此在程序中，对边界块仍编写单独的发送和接收语句，所以 MPI 引入虚拟进程 `MPI_PROC_NULL` 把边界块和内部块统一看待，这样全部通信都用 `MPI_SENDRECV` 语句实现。

虚拟进程是不存在的假想进程。在 MPI 中的主要作用是充当真实进程通信的目的或源，引入虚拟进程的目的是为了在某些情况下编写通信语句的方便。当一个真实进程向一个虚拟进程发送数据或从一个虚拟进程接收数据时该真实进程会立即正确返回，如同执行了一个空操作

主从模式实例：矩阵向量乘

## 并行程序优化
串行程序优化
（1）调用高性能库
（2）选择适当的编译器优化选项

比较通用的gcc优化选项有“-O”、“-O0”、“-O1” “-O2”、“-O3” 等
- “-O0” 表示不做优化
- “-O1”、“-O2”、“-O3” 等表示不同级别的优化，优化级别越高，生成的代码的性能可能会越好，但采用过高级别的优化会大大降低编译速度，并且可能导致错误的运行结果。
- 通常，“-O2” 的优化被认为是安全的，它可以保证程序运行的正确性。对于一般程序的编译而言，使用优化选项“-O2” 或“-O3” 就可以了。

（3）注意嵌套循环的顺序

提高cache使用效率的一个简单原则是尽量改善**数据访问的空间局部性和时间局部性**
- 空间局部性指访问了一个地址后，应该接着访问它的邻居
- 时间局部性则指对同一地址的多次访问应该在尽可能相邻的时间内完成

（4）数据分块

当处理大数组时，对数组、循环进行适当分块有助于同时改善访存的时间和空间局部性
数据分块是一项比较复杂的优化技术，好的分块方式与分块参数的确定需要对代码及cache结构进行非常细致的分析或通过大量的实验才能得到

（5）循环展开
循环展开除了能够改善数据访问的时间和空间局部性外，还由于增加了每步循环中的指令与运算的数目，亦有助于CPU多个运算部件的充分利用

并行程序优化：
（1）减少通信开销

减少通信时间的途径主要有四个：
- 减少通信量：尽量将通信局限在相邻的子区域之间，避免整个数据场的全局通信
- 提高通信粒度：减少通信次数，即尽可能将可以一起传递的数据合并起来一次传递
- 提高通信中的并发度: 即不同结点对间同时进行通信
- 使用高速互联网络

（2）全局通信尽量利用高效聚合通信算法 (调 MPI 库)

但使用标准库函数的一个缺点是整个通信过程被封装起来，无法在通信的同时进行计算工作，此时，可以自行编制相应通信代码，将其与计算过程结合起来，以达到最佳的效果

（3）挖掘算法的并行度，减少CPU 空闲等待
一些具有数据相关性的计算过程会导致并行运行的部分进程空闲等待。在这种情况下，可以考虑改变算法来**消除数据相关性**。

某些情况下数据相关性的消除是以增加计算量做为代价的。当算法在某个空间方向具有相关性时，应该考虑充分挖掘其他空间方向以及时间上的并行度

（4）负载平衡

必要时使用动态负载平衡技术，即根据各进程计算完成的情况动态地分配或调整各进程的计算任务。

动态调整负载时要考虑负载调整的开销及由于负载不平衡而引起的空闲等待对性能的影响，寻找最优负载调整方案。

（5）通信、计算的重叠: 非阻塞通信

（6）通过引入重复计算来减少通信