# 1 Introduction
Two key words:
1. Abstraction
2. Tradeoff

Tradeoff between throughput and latency
latency for a single user, throughput for the whole system
E.g. large batch size will benefit the throughput but not the latency, the serving system focus on throughput because this brings more money

Different upper system use similar infrastructures (store, compute, coordinate)

Learn how to debug in distributed systems in the labs

Vertical: scale-up
Horizontal: scale-out (multiple machines)

Strong consistency can only be defined if we have a globally synchronized clock time steps that assign a time step to each operation. This is very expensive.

Internet generally provides eventual consistency.

# 2 MapReduce
OS Level: PaaS
App Level: SaaS

Distributed systems concerns:
Scalability
Fault-Tolerance -> Correctness
Load Balance -> Performance
Consistency

Socket Program: server part, client part. Socket program is the insight of MPI.
MPI: `MPI_Send`, `MPI_Recv` , Scatter/Gather/Broadcast
'Scatter' scatters different values to many nodes, 'Broadcast' broadcasts the same values to many nodes.

Shuffle: collect intermediate key/value pairs with the same keys
We can use hash partition: hash(key)%N, to map pairs with the same key to the same partition.
In the same partition, we use sort, to further arrange the keys in finer grain. Note that a partition corresponds to a reduce task. The sorting should be done by the reduce worker locally.

MapReduce provides strong scalability, because the user only concerns about `map` and `reduce` functions, and not concerns about distribution. We can easily increase the cores for executing the MapReduce job without modifying `map` and `reduce` .
MapReduce provides strong load-balance. For `map` , if number of `map` is much larger than the number of nodes, the master just schedule `map` to a node when it is available. The situation for `reduce` is similar.
MapReduce provides strong fault-tolerance. For `map`, when a worker failed, the master just re-schedule its job to another node, as long as the document for the job to process remains unbroken. Therefore it fundamentally relies on the reliability of the underlying file system. The GFS provides reliability by replication. For `reduce` , it is similar, we should guarantee the intermediate key/value pairs intact. The intermediate key/value pairs should also be stored in the distributed file system , it is similar, we should guarantee the intermediate key/value pairs intact. The intermediate key/value pairs should also be stored in the distributed file system.

# 3 The Google File System
In RPC, the local just pass arguments to the remote, the remote executes the function and returns the results.
RPC hides the difficulties and complexity of commutating between different machines, making the remote invocation similar to local invocation.

Exactly once = At least once + duplication detection (memory based)

Heartbeat message: client tell the server it still alive

A distributed system is built upon RPC

# 4 Raft
A Turing machine is a state machine, therefore every computer program can be modeled as a state machine.

Raft is designed to directly reach consensus on multiple log entries.

The leader takes full responsibility (very similar to the primary in GFS)

Term id is similar to the proposal id in Paxos (monotonically increase)
Term id servers as the logical time, which is to used to compare who is older, who is newer. (physical time may be different for different perceivers, therefore physical time is not usable here)

The idea of Raft: if we have only one leader (proposer), the protocol can be simplified.

Availability: Muti-Paxos' availability is stronger than Raft, because Raft will be unavailable in the leader selection process. (just a better degree of high availability, both is actually high available)

Performance: leader's IOPS is the upper bound, multi-Paxos: IOPS is aggerated (multi-Paxos have potentially larger IOPS, but must be implemented very carefully)

Raft trade those for understandability.

`ApendEntries` will be periodically issued by the leader to establish authority, if a follower does not receive it for a certain time, it will start an election. 

Raft guarantees logically one term will only one leader (physically it may happens that there multiple leaders).
The older leader will issue `AppendEntires` with older term id, and the request will be denied.
Note that as long as there is a new leader, majority of voters will know now it is the new term. Therefore, the older leader will not achieve majority in the new term. (but still may be recognized by minority)
That is the guarantee brought be the Raft's leader election.

In GFS, the primary decides the index of append, In Raft, the log index to append is decided by leader. Similar again.

Older term can not prohibit other lag followers become the new leader.