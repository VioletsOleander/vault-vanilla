# 1 深度学习基础
## 1.1 基础知识
### 1.1.1 Pytorch数据操作
创建向量：`x = torch.arange`
访问形状：`x.shape`
元素数量：`x.numel`(number of elements)
改变形状：`x = x.reshape(3,4)`(3行4列)

创建全零张量，形状(2, 3, 4)：`torch.zeros(2,3,4)`
创建全一张量：`torch.ones(2,3,4)`

从list构造tensor：`x = torch.tensor([1,2,3])`
tensor与tensor之间的算术运算`+,-,*,/,**`都是elements by elements计算，按元素计算
按元素方式进行指数运算：`torch.exp(x)`

tensor连接：
`torch.cat((X,Y), dim = 0)`拓展第0维
`torch.cat((X,Y), dim = 1)`拓展第1维

使用逻辑运算符构建tensor：`X == Y`

对tensor所有元素求和会产生单个元素的tensor：`X.sum()`

形状不同的tensor运算，会调用广播机制以执行按元素操作

指定索引将元素写入矩阵：
`X[1,2] = 9`
`X[0:2,:] = 12`

python中，运行一些操作会导致为新结果分配新的内存，如：
```python
> before = id(Y)
> Y = Y + X
> id(Y) == before
False
```
执行原地操作：
```python
> Z = torch.zeros_like(Y)
> Z[:] = X + Y
# 对Z的所有元素进行改写，没有分配新的内存
```
如果在后续运算中没有重复使用X，就直接改写X的内容：
```python
> before = id(X)
> X += Y # X[:] = X + Y
> id(X) == before
True
```

tensor转换为numpy张量：
```python
> A = X.numpy()
> B = torch.tensor(A)
> type(A), type(B)
(numpy.ndarray, torch.Tensor)
```

大小为1的tensor转换为python标量：`x.item(), float(x), int(a)`

### 1.1.2 Pandas数据预处理
读取文件：
```python
import pandas as pd
data = pd.read_csv(file_name)
```

处理缺失数据：
```python
# 常用的方法有插值或删除
inputs, outputs = data.iloc[:,0:2], data.iloc[:,2] # iloc为index locate，即通过索引值索取数据，在本句代码中，前2列是inputs，最后一列是outputs
inputs.fillna(inputs.mean()) # 用均值填充，只适用于数值域

# 对于inputs中的类别值或离散值有缺失的，将NaN视为一个类别
inputs = pd.get_dummies(inputs, dummy_na = True)
```

在所有数据都为数值型之后，就可以转换为tensor了
`X, y = torch.tensor(inputs.values),torch.tensor(outputs.values)`
默认dtype = torch.float64 `

### 1.1.3 Pytorch线性代数
创建矩阵：`A = torch.arange(20).reshape(5,4)'
转置：`A.T`
对称矩阵：`A.T == A`，返回一个全部元素为True的tensor

分配新内存：`B = A.clone()`

按元素乘法：`A * B`

按指定轴求和：
```python
> A = torch.arange(40).reshape(2,5,4)
> A.shape
torch.Size([2,5,4])

> A_sum_axis0 = A.sum(axis = 0)
> A_sum_axis0.shape
torch.Size([5,4])

> A_sum_axis1 = A.sum(axis = 1)
> A_sum_axis1.shape
torch.Size([2,4])

> A.sum(axis = [0,1]).shape
torch.Size([4])
```

求均值：`A.mean() == A.sum() / A.numel()`
求某一维度的均值：`A.mean(axis=1) == A.sum(axis=1) / A.shape[1]`

求和后保持维度不变：`sum_A = A.sum(axix=1, keepdims=True)`
保持维度不变是为了利用广播机制：`A / sum_A`

在某个轴上累计求和：`A.cumsum(axis=0)`

向量的点积：`torch.dot(x,y)`
矩阵乘向量：`torch.mv(A,x)`
矩阵乘矩阵：`torch.mm(A,B)`

矩阵或向量的范数：
```python
# L2范数
torch.norm(u)
# L1范数
torch.abs(u).sum()
```

### 1.1.4 矩阵求导知识
亚导数：将导数拓展到不可微函数的导数
如：
$$\frac {\partial |x|} {\partial x} = \begin{cases}
1& if\ x> 0\\
-1& if\ x< 0\\
a & if\ x = 0,a\in[-1,1]
\end{cases}$$
在$x = 0$时，切线斜率不唯一
如：
$$\frac {\partial max(x,0)}{\partial x} = \begin{cases}
1& if\ x>0\\
0& if\ x<0\\
a& if\ x=0,a\in[-1,1]
\end{cases}$$
向量求导：
(1) $y$是标量，$\mathbf{x}$是向量
$\mathbf x = \begin{bmatrix}x_1\\ x_2\\ \vdots \\ x_n\end{bmatrix}$，$\mathbf x$是列向量

$$\frac {\partial y}{\partial \mathbf x} = [\frac {\partial y}{\partial x_1},\frac {\partial y}{\partial x_2},\cdots,\frac {\partial y}{\partial x_n}]$$
导数是行向量，实际上就是多元函数的梯度

如：$$\frac {\partial (x_1^2+2x_2^2)}{\partial \mathbf x} = [2x_1,4x_2]$$

(2)  $\mathbf y$是向量，$x$是向量
$\mathbf y = \begin{bmatrix}y_1\\ y_2\\ \vdots \\ y_n\end{bmatrix}$，$\mathbf y$是列向量

$$\frac {\partial \mathbf y}{\partial x} = 
\begin{bmatrix}
\frac {\partial y_1} {\partial x}\\ 
\frac {\partial y_2} {\partial x}\\ \vdots \\ 
\frac {\partial y_n} {\partial x}
\end{bmatrix}$$
导数是列向量，等价于每个$y_i$对$x$求导数

(3) $\mathbf y$是向量，$\mathbf x$是向量
$\mathbf x = \begin{bmatrix}x_1\\ x_2\\ \vdots \\ x_n\end{bmatrix}$，$\mathbf x$是列向量，$\mathbf y = \begin{bmatrix}y_1\\ y_2\\ \vdots \\ y_n\end{bmatrix}$，$\mathbf y$是列向量
 $$\frac {\partial \mathbf y}{\partial \mathbf x} = 
\begin{bmatrix}
\frac {\partial y_1} {\partial \mathbf x}\\ 
\frac {\partial y_2} {\partial \mathbf x}\\ \vdots \\ 
\frac {\partial y_n} {\partial \mathbf x}
\end{bmatrix} = 
\begin{bmatrix}
\frac {\partial y_1} {\partial x_1},\frac {\partial y_1} {\partial x_2},\cdots,\frac {\partial y_1} {\partial x_n}\\
\frac {\partial y_2} {\partial x_1},\frac {\partial y_2} {\partial x_2},\cdots,\frac {\partial y_2} {\partial x_n}\\
\vdots\\
\frac {\partial y_n} {\partial x_1},\frac {\partial y_n} {\partial x_2},\cdots,\frac {\partial y_n} {\partial x_n}\\
\end{bmatrix}$$

导数是矩阵，等价于每个$y_i$对$\mathbf x$求梯度

如：
$$\frac {\partial \mathbf x}{\partial \mathbf x} = \mathbf I$$
$$\frac {\partial \mathbf {Ax}}{\partial \mathbf x} = \mathbf A$$

### 1.1.5 Pytorch自动求导
链式法则：
$$\begin{aligned}
\frac {\partial y} {\partial \mathbf x}&=\frac {\partial y} {\partial u}\frac {\partial u} {\partial \mathbf x}\\
(1,n)&\quad\ (1,)(1,n)
\end{aligned}$$
$$\begin{aligned}
\frac {\partial y} {\partial \mathbf x}&=\frac {\partial y} {\partial \mathbf u}\frac {\partial \mathbf u} {\partial \mathbf x}\\
(1,n)&\quad\ (1,k)(k,n)
\end{aligned}$$
$$\begin{aligned}
\frac {\partial \mathbf y} {\partial \mathbf x}&=\frac {\partial \mathbf y} {\partial \mathbf u}\frac {\partial \mathbf u} {\partial \mathbf x}\\
(m,n)&\quad\ (m,k)(k,n)
\end{aligned}$$

torch利用链式法则构造计算图，将计算表示为一个无环图
自动求导可以前向累积，也可以反向累积
前向累积在构造图时直接计算中间结果，并将其存储
反向累积在构造图后反向计算，可以去除不需要的枝
前向累积计算一个变量的梯度的时间复杂度O(n)，空间复杂度O(1)，每次计算都要走一遍图
反向累积时间复杂度O(n)，空间复杂度O(n)，存储了中间结果，可以以O(1)的复杂度计算任意一个中间层变量的梯度
n是操作子个数(结点数)

自动求导实现：
函数$y = 2\mathbf x^T \mathbf x$，对列向量$\mathbf x$求导
`x = torch.arange(4), requires_grad=True)`构造$\mathbf x$
`x.grad`访问$\mathbf x$的梯度，默认值是None

`y = 2 * torch.dot(x, x)`计算y
`y.backward()`计算y关于$\mathbf x$的梯度
`x.grad`访问梯度，`x.grad == 4 * x`得`tensor([True,True,True,True])

默认情况下，torch会累积梯度，`x.grad.zero_()`清除梯度

将某些计算移动到记录的计算图之外：
```python
> y = x * x
> u = y.detach() # u是一个常数向量而不是关于x的函数，不在计算图内
> z = u * x 
> z.sum().backward() # z.sum() = u1x1 + u2x2 + u3x3 + u4x4
> x.grad == u

tensor([True, True, True, True])
```

## 1.2 线性回归
### 1.2.1 线性模型
**模型形式**
给定n维输入$\mathbf x = [x_1,x_2,\cdots,x_n]^T$
线性模型会有一个n维的权重$\mathbf w = [w_1,w_2,\cdots,w_n]^T$，和一个标量偏差$b$
输出是输入的加权和：$y = \langle\mathbf w,\mathbf x\rangle + b$

线性模型可以视为一个单层的神经网络

**衡量预估质量**
平方损失：$$\mathcal L(y,\hat y) = \frac 1 2(y-\hat y)^2$$
$y$是真实值，$\hat y$是估计值

**训练数据**
假设有n个样本，记$\mathbf X = [\mathbf x_1,\mathbf x_2,\cdots,\mathbf x_n]^T$，$\mathbf y = [y_1,y_2,\cdots,y_n]^T$

**参数学习**
关于给定训练数据和参数下的训练损失：
$$\begin{aligned}\mathcal L(\mathbf X,\mathbf y,\mathbf w,b) =& \frac 1 {2n}\sum_{i= 1}^n(y_i-\langle\mathbf x_i,\mathbf w\rangle-b)^2\\
= &\frac 1{2n}\|\mathbf y-\mathbf X\mathbf w-b\|^2\end{aligned}$$
即模型在每个训练样本上的损失上求均值

最小化损失来学习参数：
$$\mathbf w^*,b^* = \arg \min_{\mathbf w,b}\mathcal L(\mathbf X,\mathbf y,\mathbf w,b) $$

**显式解**
令$\mathbf X = [\mathbf X,\mathbf 1]$，$\mathbf w = \begin{bmatrix}\mathbf w \\ b\end{bmatrix}$
则损失可以简写为：
$$\begin{aligned}\mathcal L(\mathbf X,\mathbf y,\mathbf w) 
= &\frac 1{2n}\|\mathbf y-\mathbf X\mathbf w\|^2\end{aligned}$$

而：
$$\frac {\partial \mathcal L(\mathbf X,\mathbf y,\mathbf w) }{\partial \mathbf w} = \frac 1 n(\mathbf y-\mathbf X\mathbf w)^T\mathbf X $$

因为损失是凸函数，故最优解即令其梯度为0时的解：
$$ \frac 1 n(\mathbf y-\mathbf X\mathbf w)^T\mathbf X = 0\Leftrightarrow \mathbf w^*= (\mathbf X^T\mathbf X)^{-1}\mathbf X\mathbf y$$

### 1.2.2 基础优化方法
#### 1.2.2.1 梯度下降
先挑选一个初始值$\mathbf w_0$
反复执行梯度下降：
$$\mathbf w_t = \mathbf w_{t-1}-\eta\frac {\partial\mathcal L}{\partial \mathbf w_{t-1}}$$
参数向负梯度方向变化，以使得损失函数减小，步长由学习率控制

#### 1.2.2.2 小批量随机梯度下降
在整个训练集上计算梯度太昂贵，因此随机采样b个样本$i_1,i_2,\cdots,i_b$来近似损失
$$\frac 1 b\sum_{i\in I_b}\mathcal L(\mathbf x_i,y_i,\mathbf w) $$

### 1.2.3 代码实现
#### 1.2.3.1 数据集构造
通过真实的参数和随机噪声构造数据集：
```python
def synthesize_data(w, b, num_examples):
	X = torch.normal(0, 1, (num_examples, len(w)))
	y = torch.matmul(X, w) + b
	y += torch.normal(0, 0.01, y.shape)
	return X, y.reshape((-1, 1))

true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = synthesize_data(true_w, true_b, 1000)
```

采样batch：
```python
def data_iter(batch_size, features, labels):
	num_examples = len(feature)
	indices = list(range(num_examples))
	random.shuffle(indices)

	for i in range(0, num_examples, batch_size):
		batch_indices = torch.tensor(indices[i: min(i+batch_size, num_examples)])
		yield features[batch_indices], labels[batch_indices]

batch_size = 10

for X, y in data_iter(batch_size, features, labels):
	pass
```
#### 1.2.3.2 从零实现

初始化模型参数：
```python
w = torch.normal(0, 0.01, size=(2, 1), requires_grad=True)
b = torch.zeros(1, requires_grad=True)
```

定义模型：
```python
def linear_reg(X, w, b):
	return torch.matmul(X, w) + b
```

定义损失函数：
```python
def squared_loss(y_hat, y):
	return (y_hat - y.reshape(y_hat.shape))**2 / 2
```

定义优化算法：
```python
def sgd(params, lr, batch_size):
	with torch.no_grad():
		for param in params:
			param -= lr * param.grad / batch_size
			param.grad.zero_()
```

训练过程：
```python
lr = 0.03
num_epoches = 3
net = linear_reg
loss = squared_loss

for epoch in range(num_epoches):
	for X, y in data_iter(batch_size, features, labels):
		l = loss(net(X, w, b), y)
		l.sum().backward()
		sgd([w, b], lr, batch_size)
		
	with torch.no_grad():
		train_l = loss(net(features, w, b), labels)
		print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')
```

#### 1.2.3.3 PyTorch实现
```python
from torch.utils import data
import numpy as np
import torch 

true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = synthesize_data(true_w, true_b, 1000)
```

调用torch的api来构造数据迭代器：
```python
def load_array(data_arrays, batch_size, is_train=True):
	dataset = data.TensorDataset(*data_arrays)
	return data.DataLoader(dataset, batch_size, shuffle=is_train)

batch_size = 10
data_iter = load_array((features, labels), batch_size)
```

调用torch的api来构建模型：
```python
from torch import nn

net = nn.Sequential(nn.Linear(2, 1))
```

初始化模型参数：
```python
net[0].weight.data.normal_(0, 0.01)
net[0].bias.data.fill_(0)
```

实例化损失和SGD：
```python
loss = nn.MSELoss()
trainer = torch.optim.SGD(net.parameters(), lr=0.03)
```

训练过程：
```python
num_epoches = 3
for epoch in range(num_epoches):
	for X, y in data_iter:
		l = loss(net(X), y)
		
		trainer.zero_grad()
		l.backward()
		
		trainer.step()
	l = loss(net(features), labels)
	print(f'epoch {epoch + 1}, loss {l:f}')
```

## 1.3 Softmax回归
### 1.3.1 Softmax模型
**分类与回归**
回归：估计一个连续值
- 单连续数值输出(单个输出，且连续)
- 输出区间为自然区间$\mathbb R$
- 损失采用预测值和真实值的区别，如$(预测值-真实值)^2$
分类：预测一个离散类别
- 通常为多个输出，输出的个数为类别的个数
- 输出的第i个元素为第i类的置信度

**从回归到多类分类**
首先对类别进行one-hot编码：
$\mathbf y = [y_1,y_2,\cdots,y_n]^T$，其中$y_i = \begin{cases}1 & if\ i=y\\0 & otherwise\end{cases}$

然后设计损失：
- 均方损失：
	可以使用均方损失进行回归训练，置信度最大的那一类即为预测类$\hat y = \mathop{\arg\max}\limits_{i}\ o_i$
- 无校验比例：
	进一步想，对于分类来说，我们更关心的是模型可以拉开正确类和错误类之间置信度的差异，而$[0,1]$这个区间过于有限，因此我们可以设计损失为$o_y-o_i \ge \Delta (y, i)$，即回归得到的正确类和其余错误类之间的置信度的差异要超过某一个阈值
- 校验比例：
	再进一步，希望输出的置信度依然可以是概率的形式(所有值非负，且和为1)，采用softmax处理即可：$\mathbf {\hat y} = softmax(\mathbf o)$，即$\hat y_i = exp(o_i)/\sum_k exp(o_k)$(采用指数函数是为了得到非负的值，除以和是为了可以全部相加得1)
	这时的损失为预测概率$\mathbf {\hat y}$与真实概率$\mathbf y$的区别，如交叉熵

**Softmax与交叉熵损失**
交叉熵常用于衡量两个总体的区别：
$$H(\mathbf p, \mathbf q) = \sum_i -p_ilog(q_i)=-\sum_ip_ilog(q_i)$$
如果用交叉熵作为损失：
$$
\mathcal L(\mathbf y,\mathbf {\hat y}) = -\sum_iy_ilog(\hat y_i)
$$
因为$\mathbf y$为one-hot向量，容易得到：
$$\mathcal L(\mathbf y,\mathbf {\hat y})= -log(\hat y_y)$$
损失只和对于真实类的预测概率有关，为其负对数
因此交叉熵损失只是要求真实类的预测概率(置信度)要足够大，不过在softmax中，对于真实类的预测概率和对于所有类的预测概率也是相关的

计算偏导数：
$$\begin{aligned}
\mathcal L(\mathbf y,\mathbf {\hat y}) =& -\sum_iy_ilog(\hat y_i)\\
= &-\sum_iy_ilog\frac {exp(o_i)}{\sum_jexp(o_j)}\\
=& -\sum_iy_i(o_i-log[\sum_jexp(o_j)])\\
=& -\sum_iy_io_i + \sum_iy_ilog[\sum_jexp(o_j)]\\
=& -\sum_iy_io_i + log[\sum_jexp(o_j)]
\end{aligned}$$
$$\frac {\partial L(\mathbf y,\mathbf {\hat y})}{\partial o_i}= -y_i + \frac {exp(o_i)}{\sum_j exp(o_j)}=softmax(\mathbf o)_i - y_i$$
损失对于$o_i$的偏导数即预测概率与真实概率的差
因此优化时沿着逆梯度方向走，就是使得这个差越来越小

**小结**
- Softmax回归是一个多类分类模型
- 使用Softmax操作计算每个类的预测置信度(预测概率)
- 使用交叉熵衡量预测总体和真实总体的区别

### 1.3.2 基础损失函数
衡量预测值与真实值的区别，有常用的几类损失函数：
#### 1.3.2.1 L2 Loss
$$\mathcal L(y, y') = \frac 1 2(y-y')^2$$L2 Loss关于$y'$是二次函数
L2 Loss的似然函数是高斯分布
L2 Loss关于$y'$的梯度是一次函数

#### 1.3.2.2 L1 Loss
$$\mathcal L(y,y')=|y-y'| $$L1 Loss关于$y'$是一次函数
L1 Loss的似然函数是拉普拉斯分布
L1 Loss关于$y'$的梯度是分段函数
	
L1 Loss的梯度无关损失的大小，永远是常数，因此具有稳定性
L1 Loss在零点处不可导，不平滑，会在优化末期带来不稳定性

#### 1.3.3.3 Huber's Robust Loss
$$\mathcal L(y,y')=\begin{cases}|y-y'|-\frac 1 2& if\ |y-y'|>1 \\\frac 1 2(y-y')^2& otherwise\end{cases}$$结合了L1 Loss和L2 Loss 

### 1.3.3 代码实现
#### 1.3.3.1 Fashion-MNIST数据集
导入库：
```python
import torch
import torchvision
from torch.utils import data
from torchvision import transforms
```

下载Fashion-MNIST并读取：
```python
> trans = transforms.ToTensor() 
# 用于将图像从PIL格式转换为dtype=float32的Tensor格式，并除以255使得所有像素的数值都在0到1之间

> mnist_train = torchvision.datasets.FashionMNIST(root='../data',
											   train=True,
											   transform=trans,
											   download=True)
											   
> mnist_test = torchvvision.datasets.FashionMNIST(root='../data',
											   train=False,
											   transform=trans,
											   download=True)
> len(minst_train), len(mnist_test)

(60000, 10000)
```

```python
> mnist_train[0][0].shape

torch.Size([1, 28, 28]) # C * W * H
						# 黑白图片，channel=1
```

读取数据：
```python
batch_size = 256
dataloader_workers = 4 # 使用4个进程读取数据

train_iter = data.Dataloader(mnist_train, 
							 batch_size, 
							 shuffle=True, 
							 num_workers=dataloader_workers)

# 测试读一遍数据的时间
timer = Timer()
for X, y in train_iter:
	continue
print(f'{timer.stop():.2f} seconds')
```


#### 1.3.4.1 从零实现
读数据：
```python
batch_size = 256
train_iter, test_iter = load_data_fashion_mnist(batch_size)
```

展平图像为向量：
```python
num_inputs = 784 # 向量长度784
num_outputs = 10 # 共10类

		W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)
		b = torch.zeros(num_outputs, requires_grad=True)
```

对于一个矩阵应用softmax函数即逐行应用softmax函数：
$$softmax(\mathbf X)_{ij}=\frac {exp(\mathbf X_{ij})}{\sum_kexp(\mathbf X_{ik})}$$
实现softmax：
```python
def softmax(X):
	X_exp = torch.exp(X)
	partition = X_exp.sum(1, keepdim=True) # 保持其为一个二维的矩阵
	return X / partition # 应用了广播机制
```

实现softmax回归模型：
```python
def net(X):
	return softmax(torch.matmul(X.reshape(-1, W.shape[0]), W) + b)
```

实现交叉熵损失函数：
```python
def cross_entropy(y_hat, y):
	return -torch.log(y_hat[range(len(y_hat)), y]) # 利用y作为索引
```

计算预测正确样本格数：
```python
def accuracy(y_hat, y):
	if y_hat.shape[0] > 1 and y_hat.shape[1] > 1:
		y_hat = y_hat.argmax(axis=1)
	cmp = y_hat.type(y.dtype) == y
	return float(cmp.type(y.dtype).sum())
```

评估训练好的模型的准确率：
```python
def evaluate_accuracy(net, data_iter):
	if isinstance(net, torch.nn.Module):
		net.eval()
	metric = Accumulator(2) # [正确预测数，预测总数]
	for X, y in data_iter:
		metric.add(accuracy(net(X), y)), y.numel())
	return metric[0] / metric[1]
```

训练：
```python
def train_epoch(net, train_iter, loss, updater):
	if isinstance(net, torch.nn.Module):
		net.train()
	metric = Accumulator(3)
	for X, y in train_iter:
		y_hat = net(X)
		l = loss(y_hat, y)
		if isinstance(updater, torch.optim.Optimizer):
			updater.zero_grad()
			l.backward()
			updater.step()
			metric.add(float(l) * len(y),    
					   accuraty(y_hat,y),
					   y.numel())
		else:
			l.sum().backward()
			updater(X.shape[0])
			metric.add(float(l.sum()), 
					   accuracy(y_hat,y), 
					   y.numel())
		return metric[0] / metric[2], metric[1] / metric[2]

for epoch in range(num_epochs):
	train_loss, train_acc = train_epoch(net, train_iter, cross_entropy, updater)
	test_acc = evaluate_accuracy(net, test_iter)
```

#### 1.3.4.2 PyTorch实现
```python
net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))

def init_weights(m):
	if type(m) == nn.Linear:
		nn.init.normal_(m.weight, std=0.01)
		
net.apply(init_weights)

loss = nn.CrossEntropyLoss()

trainer = torch.optim.SGD(net.parameters(), lr=0.1)
```

## 1.4 感知机
### 1.4.1 感知机模型
#### 1.4.1.1 单层感知机
$$\begin{aligned}o &= \sigma(\langle\mathbf w, \mathbf x\rangle + b)\\\\
\sigma(x) &= \begin{cases} 1& if\ x >0\\0&otherwise\end{cases}
\end{aligned}$$
即线性计算+激活函数
输出只有两种离散值(可以是1/-1，可以是1/0)
(线性回归输出实数，Softmax回归输出概率)
感知机用于解决线性二分类问题
感知机是最早的AI模型之一

**训练感知机**
**initialize** $w = 0$ **and** $b = 0$
**repeat**
  **if** $y_i[\langle\mathbf w, \mathbf x\rangle + b]\le 0$ **then** (小于等于0说明分类分错了)
	$w \leftarrow w + y_ix_i$ **and** $b \leftarrow b + y_i$
  **end if**
**until** all classified correctly

该算法等价于使用 `batch_size = 1` 的梯度下降，损失函数为：$$\mathcal L (y,\mathbf x,\mathbf w) = max(0,-y\langle\mathbf w,\mathbf x\rangle)$$

**收敛定理**
假设：
- 所有数据在一个半径为$r$的圆内
- 存在一个余量$\rho$，可以使数据完全被分为两类，即对所有样本都满足：$$y(\mathbf x^T\mathbf W + b) \gt \rho\quad subject.to.\quad\|\mathbf w\|^2+b^2\le1$$
那么感知机保证在$(r^2+1)/\rho^2$步后收敛

**XOR问题**
感知机只能产生线性分割面，不能拟合异或函数

#### 1.4.1.2 多层感知机
多层感知机即添加了隐藏层

**单隐藏层二分类**
输入$\mathbf x \in \mathbb R^n$，隐藏层$\mathbf W_1 \in \mathbb R^{m\times n}, \mathbf b_1 \in \mathbb R^m$，输出层$\mathbf w_2\in \mathbb R^m,b_2\in \mathbb R$
$$\begin{aligned}\mathbf h &= \sigma(\langle\mathbf W_1, \mathbf x\rangle + \mathbf b_1)\\\\
o &= \mathbf w_2\mathbf h+b_2
\end{aligned}$$
$\sigma$是按元素激活的函数

需要非线性的激活函数引入非线性，否则仍然是$o$仍然是$\mathbf x$的线性函数

常用的简单激活函数：
- $\sigma(x) = \begin{cases} 1 & if\ x > 0  \\ 0 & otherwise\end{cases}$
- $sigmoid(x) = 1/ (1+ e^{-x}))\quad x\in \mathbb R, sigmoid(x) \in (0,1)$
- $tanh(x) = (1-e^{-2x}) / (1 + e^{-2x})\quad x\in \mathbb R, tanh(x) \in (-1,1)$
- $ReLU(x) = max(x,0)$

**单隐藏层多分类**
区别不大，比之前的Softmax回归模型多算了一层而已

输入$\mathbf x \in \mathbb R^n$，隐藏层$\mathbf W_1 \in \mathbb R^{m\times n}, \mathbf b_1 \in \mathbb R^m$，输出层$\mathbf W_2\in \mathbb R^{m\times k},\mathbf b_2\in \mathbb R^k$
$$\begin{aligned}\mathbf h &= \sigma(\langle\mathbf W_1, \mathbf x\rangle + \mathbf b_1)\\\\
\mathbf o &= \mathbf W_2\mathbf h+\mathbf b_2 \\\\
\mathbf y &= softmax(\mathbf o)
\end{aligned}$$
最后一层还是一样的：
$$y_1,y_2,\cdots,y_k = softmax(o_1,o_2,\cdots,o_k)$$

**多隐藏层**
$$\begin{aligned}\mathbf h_1 &= \sigma(\mathbf W_1\mathbf x+ \mathbf b_1)\\
\mathbf h_2 &= \sigma(\mathbf W_2\mathbf h_1+ \mathbf b_2) \\
\mathbf h_3 &= \sigma(\mathbf W_3\mathbf h_2+ \mathbf b_3) \\
\mathbf o &=\mathbf W_4\mathbf h_3 + \mathbf b_4
\end{aligned}$$

### 1.4.2 代码实现
#### 1.4.2.1 从零实现
```python
num_inputs, num_outputs, num_hiddens = 784, 10, 256

W1 = nn.Parameter(
	torch.randn(num_inputs, num_hiddens, requires_grad=True)
)
b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))
W2 = nn.Parameter(
	torch.randn(num_hiddens, num_outputs, requires_grad=True)
)
b2 = nn.Parameter(torch.zeros(num_outputs, reqiures_grad=True))

params = [W1, b1, W2, b2]

# 激活函数
def relu(X):
	a = torch.zeros_like(X)
	return torch.max(X, a)

# 模型
def net(X):
	X = X.reshape((-1, num_inputs))
	H = relu(X @ W1 + b1)
	return (H @ W2 + b2)

# 损失
loss = nn.CrossEntropyLoss()
```

#### 1.4.2.2 PyTroch实现
```python
net = nn.Sequential(
	nn.Flatten(), nn.Linear(784, 256), nn.ReLu(), nn.Linear(256, 10))

def init_weight(m):
	if type(m) == nn.Linear:
		nn.init.normal_(m.weight, std=0.01)

net.apply(init_weight)

batch_size, lr, num_epoches = 256, 0.1, 10

loss = nn.CrossEntropyLoss()
trainer = nn.optim.SGD(net.parameters(), lr=lr)
```

## 1.5 过拟合与欠拟合
### 1.5.1 模型选择
**训练误差和泛化误差**
- 训练误差：模型在训练数据上的误差
- 泛化误差：模型在新数据上的误差

**验证数据集和测试数据集**
- 验证集：用来评估模型好坏的数据集
	训练集用于训练模型参数，而验证集用于选择模型超参数
	验证集从训练集中划分，不要和训练数据有交集
	常用5/10折交叉验证划分训练集和验证集，注意交叉验证的验证误差是所有的5个/10个验证误差的平均值
	考虑计算资源的限制，数据集较大时K应取得小一点，数据集较小时K应取得大一点
- 测试集：只用一次的数据集

### 1.5.2 过拟合与欠拟合
四种情况：
- 模型容量低+数据简单：正常
- 模型容量高+数据复杂：正常
- 模型容量高+数据简单：过拟合(模型有能力记住每个样本及其噪音以达到极高的训练精度，但是缺少泛化性)
- 模型容量低+数据复杂：欠拟合(模型能力不足)

也就是说，模型容量必须匹配数据复杂度，否则容易导致过拟合或欠拟合

**模型容量**
指模型拟合各种函数的能力
低容量的模型难以很好地拟合训练数据，高容量的模型有可能记住所有的训练数据

一个常用的调参策略是模型容量从小到大

我们通常可以使用训练误差和泛化误差的差异衡量过拟合的程度

**估计模型容量**
在不同种类的算法之间，模型容量难以比较(如树模型和神经网络模型)

如果给定一个模型种类，决定模型容量的两个主要因素一般是：
- 可以学习的参数的个数
- 参数值的选择范围

**VC维**
对于一个分类模型，它的VC维等于一个最大的数据集的大小，这个数据集应满足：不论我们如何给定标号，都存在一个模型可以对其进行完美分类

线性分类器的VC维：
- 输入维度=2，输出维度=1的感知机，VC维=3
	如果平面上只有三个点，则不论怎么标号，该模型都可以任意分类，但如果是4个点，可以标号使其成为异或问题，则模型不能完美解决(一条直线无法解决异或问题)
- 输入维度=N，输出维度=1的感知机，VC维=N+1
- 一些多层感知机的VC维为$O(Nlog_2N)$

VC维衡量了一个模型的理论的能力/容量，但在深度学习中很少使用，因为衡量不够准确，且稍微复杂的模型的VC维的计算也极为困难

**数据复杂度**
- 样本个数
- 每个样本的元素个数(如图片的像素，通道数)
- 样本中的时间，空间结构是否复杂(如视频)
- 数据的多样性(如类别数)

## 1.6 正则化
### 1.6.1 权重衰退
权重衰退是最常见的避免过拟合的方法
权重衰退的思路是通过L2的正则项使得模型的参数不会过大，通过控制模型参数的选择范围的方式，从而控制模型复杂度

控制模型容量的两种方法：
- 控制模型参数的数量
- 控制模型参数的取值/选择范围

权重衰退利用了控制模型参数的取值/选择范围来控制模型容量：
- 使用均方范数作为硬性限制
	$$min\ [\mathcal L(\mathbf w,b)]\quad subject.to.\ \|\mathbf w\|\le \theta$$
	对优化加入了约束条件
	因为需要明确指定$\theta$，所以称为硬性限制
	
	通常不会限制偏移$b$，因为数学上讲对$b$限不限制没有差别
	小的$\theta$意味着更强的正则项
- 使用均方范数作为柔性限制
	根据拉格朗日乘子法，事实上对于$$min\ [\mathcal L(\mathbf w,b)]\quad subject.to.\ \|\mathbf w\|\le \theta$$中的每个$\theta$，都可以找到$\lambda$，将该约束优化问题等价于$$min\ [\mathcal L (\mathbf w, b)]+\frac \lambda 2\|\mathbf w\|^2$$
	因此对于$\theta$作调节可以等价于对$\lambda$作调节
	因为避免了明确指定$\theta$，所以称为柔性限制
	
	$\lambda$作为超参数，控制了正则项的重要程度
	$\lambda \to 0$等价于$\theta \to \infty$，无作用
	$\lambda \to \infty$等价于$\theta \to 0$，会使得优化最优解$\mathbf w^* \to \mathbf 0$

L2约束下的参数更新：
- 计算梯度
	$$\frac {\partial(\mathcal L (\mathbf w, b)+\frac \lambda 2\|\mathbf w\|^2)}{\partial \mathbf w}= \frac {\partial \mathcal L(\mathbf w, b)}{\partial\mathbf w}+\lambda\mathbf w$$
 - 更新参数，学习率为$\eta$
	$$\mathbf w_{t+1}= (1-\eta\lambda)\mathbf w_t-\eta\frac {\partial\mathcal L (\mathbf w_t, b_t)}{\partial \mathbf w_t}$$
	可以发现L2约束下的参数更新和没有约束的参数更新的差异在于多了一个$-\eta\lambda \mathbf w_t$的项
	通常$\eta\lambda < 1$，可以发现L2约束下的参数更新等价于在原来的基础上增加了一步：在每次的更新前按比例缩放原来的权重
	因此我们可以称其为权重衰退

### 1.6.3 Dropout
动机：一个好的模型需要对输入数据的扰动鲁棒

增强鲁棒性的方法：加入噪音
- Tikhonov正则：在数据中加入噪音
	(人为地加入随机噪音，和数据中固定包含的噪音不同)
- Dropout：不是在输入加入噪音，而是在模型的层之间加入噪音
	Dropout将一些输出项随机置0以控制模型复杂度
	Dropout常作用于多层感知机的隐藏层输出上

**无偏差地加入噪音**
$\mathbf x$是模型中一层到下一层的输入，我们对$\mathbf x$加入噪音，将其变为$\mathbf x'$，但是我们要求$E[\mathbf x'] = \mathbf x$，即不改变期望值

为此，Dropout对每个元素进行如下扰动：$x_i' = \begin{cases}0& with \ probility\ p \\ x_i/(1-p)&otherwise\end{cases}$

显然$E[x_i'] = p\times 0 + (1-p)\times[x_i/(1-p)] = x_i$，故$E[\mathbf x'] = \mathbf x$

**训练中使用Dropout**
我们一般将Dropout作用在隐藏全连接层的输出上，如：
$$\begin{aligned}
\mathbf h &= \sigma(\mathbf W_1\mathbf x + \mathbf b_1)\\
\mathbf h' &= dropout(\mathbf h) \\
\mathbf o &= \mathbf W_2\mathbf h' + \mathbf b_2\\
\mathbf y &= softmax(\mathbf o)
\end{aligned}$$
**推理中使用Dropout**
注意正则项一般只在训练中使用，我们使用正则项以影响训练时模型参数的更新
而Dropout本质也是正则项的一种，因此在推理中，我们也不会使用Dropout
或者说，在推理中$\mathbf h = dropout(\mathbf h)$，输出输入本身，保证确定性的输出

## 1.7 数值稳定性

### 1.7.1 数值稳定性
**神经网络的梯度**
考虑$d$层的神经网络：
$$\begin{aligned}
\mathbf h^t &= f_t(\mathbf h^{t-1}) \\
y &= \mathcal L\circ f_d\circ\cdots\circ f_1(\mathbf x)
\end{aligned}$$
损失$\mathcal L$关于参数$\mathbf W_t$的梯度：
$$\frac {\partial \mathcal L}{\partial \mathbf W^t} = \frac {\partial \mathcal L}{\partial \mathbf h^d}\frac {\partial \mathbf h^d}{\partial \mathbf h^{d-1}}\cdots\frac {\partial \mathbf h^{t+1}}{\partial \mathbf h^t}\frac {\partial \mathbf h^t}{\partial \mathbf W^t}$$
计算这次梯度需要进行$d-t$次的矩阵乘法

**数值稳定性的主要两个问题**
- 梯度爆炸：$1.5^{100} \approx 4\times 10^{17}$
- 梯度消失：$0.8^{100} \approx 2\times 10^{-10}$
当数值过大或者过小，都会导致数值问题
根本原因在于多次的累乘

**MLP中的梯度计算**
有如下多层感知机(为了简单省略了偏移项)：
$$\begin{aligned}
f_t(\mathbf h^{t-1}) &= \sigma(\mathbf W^t\mathbf h^{t-1})
\end{aligned}$$
其中$\sigma$是激活函数

则：
$$\frac {\partial \mathbf h^t}{\partial \mathbf h^{t-1}} = diag(\sigma'(\mathbf W^t\mathbf h^{t-1}))(\mathbf W^t)^T$$
其中$\sigma'$是$\sigma$的导函数

因此：
$$\prod_{i=t}^{d-1}\frac {\partial \mathbf h^{i+1}}{\partial \mathbf h^{i}} = \prod_{i=t}^{d-1}diag(\sigma'(\mathbf W^i\mathbf h^{i-1}))(\mathbf W^i)^T$$

**梯度爆炸**
若使用ReLU作为激活函数：
$$\sigma(x) = max(0,x),\sigma'(x) = \begin{cases}1\ if \ x>0\\0\ otherwise\end{cases}$$
则$$\prod_{i=t}^{d-1}\frac {\partial \mathbf h^{i+1}}{\partial \mathbf h^{i}} = \prod_{i=t}^{d-1}diag(\sigma'(\mathbf W^i\mathbf h^{i-1}))(\mathbf W^i)^T$$中的一些元素会来自于$$\prod_{i=t}^{d-1}(\mathbf W^i)^T$$而另一些元素为0

如果$\mathbf W^i$中的值大部分大于1，并且$d-t$很大，则显然结果的值也会很大，就容易导致梯度爆炸

梯度爆炸的问题：
- 值超出值域，值溢出
	对于fp16尤为严重(fp16的取值区间是$[6e-5,6e4]$)
- 对学习率敏感
	如果学习率大了，更新的步长大，容易带来大的参数值，进而导致更大的梯度，带来更大的参数值，最后发生值溢出
	如果学习率小了，容易导致训练无进展
	学习率的有效范围会变得很小，我们可能需要在训练过程中不断调整学习率

**梯度消失**
若使用sigmoid作为激活函数：
$$\sigma(x) = \frac 1 {1+e^{-x}},\sigma'(x) = \sigma(x)(1-\sigma(x))$$
则$$\prod_{i=t}^{d-1}\frac {\partial \mathbf h^{i+1}}{\partial \mathbf h^{i}} = \prod_{i=t}^{d-1}diag(\sigma'(\mathbf W^i\mathbf h^{i-1}))(\mathbf W^i)^T$$
中的元素值可能会是$d-t$个小数值的乘积，导致梯度消失

梯度消失的问题：
- 梯度值变为0，导致训练没有进展
	同样对于fp16尤为严重
	而当梯度变为0，无论我们如何选择学习率，训练都不会有进展
- 无法让神经网络更深
	梯度消失对于网络的底部层尤为严重，因此会导致仅仅只有顶部层训练得比较好

### 1.7.2 模型初始化与激活函数
**让训练更加稳定**
目标：让梯度值在合理的范围内，如$[1e^{-6},1e3]$
思路：
- 让乘法变加法，如LSTM/ResNet
- 归一化：将梯度归一化，将梯度裁剪
- 合理的初始权重和激活函数

**合理的初始权重和激活函数**
如果希望保持一个数值的稳定性，我们的一个想法就是把每一层的输出和梯度都看作随机变量，并且让它们的均值和方差在每一层都保持一致
即对$\forall i, t$，都有：
$$\begin{aligned}
E[h^t_i] = 0&,Var[h_i^t] = a\\ \\
E\left[\frac {\partial \mathcal L}{\partial h_i^t}\right] = 0&,Var\left[\frac {\partial \mathcal L}{\partial h_i^t}\right] = b
\end{aligned}$$

为了满足这个性质，我们需要对初始化方法和激活函数进行选取

**MLP如何初始化权重/选取激活函数**
假设$w_{i,j}^t$是独立同分布的，并且$E[w_{i,j}^t]=0,Var[w_{i,j}^t]=\gamma_t$

假设$h_i^t$是独立同分布的，且$E[h_i^t] = 0$
假设$h_i^{t-1}$和$w_{i,j}^t$是相互独立的
(1) 假设激活函数为恒等运算$\sigma(x) = x$，即$\mathbf h^t = \mathbf W^t\mathbf h^{t-1}$，其中$\mathbf W^t \in \mathbb R^{n_t\times n_{t-1}}$

则对于正向计算：
$$E[h_i^t] = E\left[\sum_jw_{i,j}^th_j^{t-1}\right]=\sum_jE[w_{i,j}^th_j^{t-1}]=\sum_jE[w_{i,j}^t]E[h_j^{t-1}]=0$$
$$\begin{aligned}
Var[h_i^t] &= E[(h_i^t)^2]-E^2[h_i^t]=E[(h_i^t)^2]\\
&=E\left[\left(\sum_jw_{i,j}^th_j^{t-1}\right)^2\right]\\
&=E\left[\sum_j(w_{i,j}^t)^2(h_j^{t-1})^2+\sum_{j\ne k}w_{i,j}^tw_{i,k}^th_j^{t-1}h_k^{t-1}\right]\\
&=E\left[\sum_j(w_{i,j}^t)^2(h_j^{t-1})^2\right]\\
&=\sum_jE\left[(w_{i,j}^t)^2(h_j^{t-1})^2\right]\\
&=\sum_jE[(w_{i,j}^t)^2]E[(h_j^{t-1})^2]\\
&=\sum_jVar[w_{i,j}^t]Var[h_j^{t-1}]\\
&= n_{t-1}\gamma_tVar[h_j^{t-1}]
\end{aligned}$$
如果我们希望输入的方差和输出的方差一样，即$Var[h_i^t] = Var[h_i^{t+1}]$，则要求：
$$n_{t-1}\gamma_t = 1$$


类似地，我们知道，若没有激活函数：$\frac {\partial \mathcal L}{\partial \mathbf h^{t-1}} = \frac {\partial \mathcal L}{\partial \mathbf h^t}\mathbf W^t$
则
$$\left(\frac {\partial \mathcal L}{\partial \mathbf h^{t-1}}\right)^T =\left(\mathbf W^t\right)^T \left(\frac {\partial \mathcal L}{\partial \mathbf h^t}\right)^T$$
并且我们假设$\frac {\partial \mathcal L}{\partial h_i^t}$是独立同分布的，且
$$E\left[\frac {\partial \mathcal L}{\partial h_i^t}\right] = 0$$
我们还假设$\frac {\partial \mathcal L}{\partial h_i^t}$和$w_{i,j}^t$是相互独立的

则对于反向计算：
$$Var\left[\frac {\partial \mathcal L}{\partial h_i^{t-1}}\right] = n_t\gamma_tVar\left[\frac {\partial \mathcal L}{\partial h_i^t}\right] $$
如果我们希望方差一样，即$Var\left[\frac {\partial \mathcal L}{\partial h_i^{t-1}}\right] = Var\left[\frac {\partial \mathcal L}{\partial h_i^t}\right]$，则要求：
$$n_{t}\gamma_t = 1$$

显然$n_{t-1}\gamma_t = 1$和$n_{t}\gamma_t = 1$难以同时满足
因此需要权衡折中，Xavier初始化方法要求$\gamma_t(n_{t-1}+n_t)/2=1$
即：$$\gamma_t = \frac 2 {n_{t-1}+n_t}$$
以此确定了方差，因此如果采用正态分布进行初始化，那么
$$w_{i,j}^t\sim \mathcal N\left(0,\sqrt{\frac 2 {n_{t-1}+n_t}}\right)$$
如果采用均匀分布进行初始化，那么
$$w_{i,j}^t\sim \mathcal U\left(-\sqrt{\frac 6 {n_{t-1}+n_t}},\sqrt{\frac 6 {n_{t-1}+n_t}}\right)$$

Xavier的思想就是权重初始化时，根据输入输出维度来决定方差大小，或者说根据输入输出来适配权重形状变换，以使得每一层的输出的方差和梯度的方差尽量处于一个恒定的范围内

(2) 假设激活函数为线性运算$\sigma(x) = \alpha x+\beta$，即$\mathbf {h^t}' = \mathbf W^t\mathbf h^{t-1}, \mathbf h^t = \sigma(\mathbf {h^t}')$
则对于正向计算：$$E[h_i^t] = E[\alpha {h_i^t}'+\beta]$$
若假设$h_i^t$是独立同分布的，且$E[h_i^t] = 0$
则易知$E[{h_i^t}'] = 0$，则$E[h_i^t] = E[\alpha {h_i^t}'+\beta] = \beta$
我们令$\beta = 0$，以使得对$\forall i,t$都满足$E[h_i^t] = 0$

同理：
$$\begin{aligned}
Var[h_i^t] &= E[(h_i^t)^2]-E^2[h_i^t]\\
&=E[(\alpha {h_i^t}'+\beta)^2] - \beta^2\\
&=E[\alpha^2 ({h_i^t}')^2+2\alpha\beta{h_i^t}'+\beta^2] - \beta^2\\
&=\alpha^2Var[{h_i^t}']
\end{aligned}$$
激活函数的输入和输出的方差相差了$\alpha^2$倍，因此我们令$\alpha=1$，以使其保持不变

则对于反向计算有同样的结论，即在$\beta = 0,\alpha=1$时期望保持为0和方差保持不变

(3) 对于常用的激活函数
对其进行多项式展开：
$sigmoid(x) = 1/2 + x/4 - x^3/48 + O(x^5)$
$tanh(x) = 0 + x - x^3/3 + O(x^5)$
$relu(x) = 0 + x\quad for\  x \ge 0$

显然对于tanh和relu，在$x=0$附近时，和$f(x) = x$近似
而对于sigmoid，我们要对其进行调整：$\sigma(x) = 4\times sigmoid(x) -2 = x - x^3/12 + O(x^5)$
则在$x=0$附近时，$\sigma(x)$也和恒等函数近似

因此，使用tanh/relu/调整的sigmoid作为激活函数，再配合Xavier方法进行权重初始化，可以使得MLP的权重和梯度都保持一定的数值稳定性

# 2 卷积神经网络
## 2.1 PyTorch神经网络基础
### 2.1.1 通过继承构造模型
通过 `nn.Sequential` 构造MLP：
```python
from torch import nn
from torch.nn import Functional as F

net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256,10))

X = torch.rand(2, 20)
net(X)
```
其中 `nn.Sequential` 定义了一个特殊的 `Module` ，任意的模型和网络中任意的一层都是 `Module` 的子类

通过继承 `Module` 自定义普通块：
```python
class NLP(nn.Module):
	def __init__(self):
		super().__init__()
		self.hidden = nn.Linear(20, 256)
		self.out = nn.Linear(256, 10)

	def forward(self, X):
		return self.out(F.relu(self.hidden(X)))

net = NLP()
net(X)
```

通过继承 `Module` 自定义顺序块：
```python
class MySequential(nn.Module):
	def __init__(self, *args):
		super().__init__()
		for block in args:
			self._modules[block] = block # self._modules是一个ordered_dictionary, 按插入顺序排列

	def forward(self, X):
		for block in self._modules.values():
			X = block(X)
		return X

net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256,10))
net(X)
```

通过继承 `nn.Module` 自定义一个类的灵活性显然高于简单调用 `nn.Sequential` 将各层连接起来

### 2.1.2 模型参数管理
构建模型(单隐藏层的MLP)：
```python
net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))
X = torch.rand(size=(2, 4))
net(X)
```

**访问参数**
某一个 `Module` 的状态字典：
```python
> print(net[2].state_dict())

OrderedDict([('weight', tensor(...)), ('bias', tensor(...))])
```

某一个 `Module` 的具体参数：
```python
> print(type(net[2].bias)) # 直接访问类的成员变量, 实际也是一个对象
<class 'torch.nn.parameter.Parameter'>

> print(net[2].bias) 
Parameter containing:
tensor([-0.3389], requires_grad=True)

> print(net[2].bias.data) # 直接访问数据
tensor([-0.3389])

> net[2].weight.grad == None # 直接访问梯度，因为还没有计算，梯度为None
True 
```

某一个 `Module` 的所有参数：
```python
> print(*[(name, param.shape) for name, param in net[0].named_parameters()])

('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))

> print(*[(name, param.shape) for name, param in net.named_parameters()])

('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))

# 通过某参数的名字我们也可以通过 state_dict 对其访问
> net.state_dict()['2.bias']

tensor([-0.3389])
```

**初始化参数**
初始化整个模型：
```python
def init_normal(m):
	if type(m) == nn.Linear:
		nn.init.normal_(m.weight, mean=0, std=0.01)
		nn.init.zeros_(m.bias)

net.apply(init_normal)
```

初始化某一层：
```python
def xavier(m):
	if type(m) == nn.Linear:
		nn.init.xavier_uniform_(m.weight)

def init_42(m):
	if type(m) == nn.Linear:
		nn.init.constatn_(m.weight, 42)

net[0].apply(xavier)
net[2].apply(init_42)
```

**参数绑定/共享权重**
```python
shared = nn.Linear(8, 8) 
net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), shared, nn.ReLU(), shared, nn.ReLU(), nn.Linear(8, 1)) # 有两个隐藏层共享权重，或者说就是完全一样
```

### 2.1.3 通过继承自定义层
构造一个没有任何参数的自定义层：
```python
class CenteredLayer(nn.Module):
	def __init__(self):
		super().__init__()
	def forward(self, X):
		return X - X.mean()
layer = CenteredLayer()
```

构造一个带有参数的自定义层：
```python
class MyLinear(nn.Module):
	def __init__(self, in_units, units):
		super().__init__()
		self.weight = nn.Parameter(torch.randn(in_units, units))
		self.bias = nn.Parameter(torch.randn(units,))
	def forward(self, X):
		linear = torch.matmul(X, self.weight.data) + self.bias.data
		return F.relu(linear)

dense = MyLinear(5, 3)
```

### 2.1.4 PyTorch文件读写
加载和保存张量：
```python
x = torch.arange(4)
torch.save(x, 'x_file')
x_ = torch.load('x_file')
```

加载和保存张量的list：
```python
y = torch.zeros(4)
torch.save([x,y], 'x_y_files')
x_, y_ = torch.load('x_y_files')
```

加载和保存key为张量的dict：
```python
mydict = {'x': x, 'y': y}
torch.save(mydict, 'mydict')
mydict_ = torch.load('mydict')
```

加载和保存模型参数：
```python
class MLP(nn.Module):
	def __init__(self):
		super().__init__()
		self.hidden = nn.Linear(20, 256)
		self.output = nn.Linear(256, 10)
	def forward(self, x):
		return self.output(F.relu(self.hidden(x)))

net = MLP()

# 以字典形式存储模型参数
torch.save(net.state_dict(), 'mlp.params')

# 读取模型参数
clone = MLP()
clone.load_state_dict(torch.load('mlp.params'))
```

## 2.2 从全连接到卷积
### 2.2.1 从全连接到卷积
**用全连接层连接图片的参数量**
使用一个还不错的相机采集图片，一个通道有一千二百万像素，即12M像素，则一个RGB图片将有36M像素
如果采用全连接，将会需要大量参数，比如和一个大小为100的隐藏层进行全连接需要100乘以36M即36亿(3.6B)个参数

**在图片中识别模式(pattern)的两个原则**
平移不变性：模式位于图片的任意位置都不影响对它的识别
局部性：不需要整张图片，只需要包含模式的一个局部图片块即可识别

**将两个原则应用到全连接层**
现在考虑全连接层的输入输出的形状为矩阵，则权重考虑为4维的张量：
$h_{i,j} = \sum_{k, l} w_{i,j,k,l}x_{k,l}$
若令$v_{i,j,a,b} = w_{i,j,i+a,j+b}$，则
$h_{i,j} = \sum_{a,b}v_{i,j,a,b}x_{i+a,j+b}$

考虑局部性：
我们现在有：$h_{i,j} = \sum_{a,b}v_{i,j,a,b}x_{i+a,j+b}$
而评估$h_{i,j}$时，不需要用远离$x_{i,j}$的参数，即不需要看总体，看局部即可
故令$|a|,|b| > \Delta$时，使得$v_{i,j,a,b} = 0$
因此得到：$h_{i,j} = \sum_{a=-\Delta}^\Delta \sum_{b=-\Delta}^\Delta v_{i,j,a,b}x_{i+a,j+b}$

考虑平移不变性：
我们现在有：$h_{i,j} = \sum_{a=-\Delta}^\Delta \sum_{b=-\Delta}^\Delta v_{i,j,a,b}x_{i+a,j+b}$
对于输出图片的两个像素点$h_{i_1,j_1},h_{i_2,j_2}$，如果当它们对应的局部的模式是完全相同的，即输入完全相同，有：
$h_{i_1,j_1} = \sum_{a=-\Delta}^\Delta \sum_{b=-\Delta}^\Delta v_{i_1,j_1,a,b}x_{i_1+a,j_1+b}$
$h_{i_2,j_2} = \sum_{a=-\Delta}^\Delta \sum_{b=-\Delta}^\Delta v_{i_2,j_2,a,b}x_{i_2+a,j_2+b}$
而不希望$x$的平移导致$h$的平移，即$h_{i_1,j_1},h_{i_2,j_2}$不应该因为$i_1\ne i_2, j_1\ne j_2$而导致不同，因此令$v_{i,j,a,b} = v_{a,b}$，则$v$的大小现在和模式的绝对的位置$i,j$无关，换句话说就是卷积核的权重与输入的位置是无关的(保持不变)
因此得到：$h_{i,j} = \sum_{a=-\Delta}^\Delta \sum_{b=-\Delta}^\Delta v_{a,b}x_{i+a,j+b}$

因此在全连接层上应用平移不变性和局部性，就可以得到卷积层

**卷积层**
输入$\mathbf X: n_h \times n_w$，核$\mathbf W: k_h\times k_w$，偏差$b\in \mathbb R$
输出$\mathbf Y: (n_h-k_h+1)\times(n_w-k_w+1)$
$\mathbf Y = \mathbf X \star \mathbf W + b$，其中$\mathbf W,b$是可以学习的参数

一维卷积：$y_i = \sum_{a=1}^h w_ax_{i+a}$(文本，语言，时序序列)
二维卷积：$y_{i,j} = \sum_{a=1}^h\sum_{b=1}^w w_{a,b}x_{i+a,j+b}$(图像)
三维卷积：$y_{i,j,k} = \sum_{a=1}^h\sum_{b=1}^w\sum_{c=1}^d w_{a,b,c}x_{i+a,j+b,k+c}$(视频，医学图像，气象地图)

交叉相关：$h_{i,j} = \sum_{a=-\Delta}^\Delta \sum_{b=-\Delta}^\Delta v_{a,b}x_{i+a,j+b}$
卷积：$h_{i,j} = \sum_{a=-\Delta}^\Delta \sum_{b=-\Delta}^\Delta v_{-a,-b}x_{i+a,j+b}$
神经网络中的卷积实际上是交叉相关，也就是数学上的卷积的对称操作，不等价于数学上的卷积

因此卷积层实质就是将输入和核矩阵进行交叉相关运算，再加上偏移后得到输出

### 2.2.2 代码实现卷积
```python
def corr2d(X, K): 
	# 计算二维互相关
	h, w = K.shape
	Y = torch.zeros((X.shape[0] - h + 1, X.shape[0] - w + 1))
	for i in range(Y.shape[0]):
		for j in range(Y.shape[1]):
			Y[i, j] = (X[i: i + h, j: j+h] * K).sum()
	return Y

class Conv2D(nn.Module):
	# 实现二维卷积层
	def __init__(self, kernel_size):
		super().__init__()
		self.weight = nn.Parameter(torch.rand(kernel_size))
		self.bias = nn.Parameter(torch.zeros(1))
	def forward(self, x):
		return corr2d(x, self.weight) + self.bias

# 应用卷积层检测图像中不同颜色的边缘
X = torch.ones((6,8))
X[:, 2:6] = 0
K = torch.tensor([[1.0, -1.0]]) # 只能检测垂直的边缘
Y = corr2d(X, K)
# 输出中的1代表从白色到黑色的边缘，-1代表从黑色到白色的边缘

# 卷积核参数学习
conv2d = nn.Con2d(1, 1, kernel_size=(1,2), bias=False)
X = X.reshape((1,1,6,8))
Y = Y.reshape((1,1,6,7))

for i in range(10):
	Y_hat = conv2d(X)
	l = (Y_hat - Y)**2
	conv2d.zero_grad()
	l.sum().backward()
	conv2d.weight.data[:] -= 3e-2 * conv2d.weight.grad
	
```

## 2.3 卷积层的超参数
### 2.3.1 填充(padding)
一般情况下：
如果步长为1，填充为0，输入特征图的形状为$(n_h\times n_w)$，卷积核的形状为$(k_h\times k_w)$，则应用一次卷积，输出特征图形状为$(n_h - k_h + 1) \times (n_w - k_w + 1)$

例如：
给定(32, 32)的输入图像，如果我们应用(5, 5)大小的卷积核
应用一次，在第一层得到(28, 28)大小的特征图(一次减少4个像素)，
应用七次，在第七层得到(4, 4)大小的特征图

如果希望更快地减小输出特征图的大小，可以用更大的卷积核

在例子中，我们可以发现，即使卷积核不是特别大(如$5\times 5$)，在原始图像本身不大的情况下(如$32\times 32$)，多应用几次卷积，就不能在继续应用下去了，因为输出特征图的大小已经小于卷积核的大小，网络的深度被限制了

利用填充可以解决这个问题，填充即在输入图的周围添加额外的行/列，扩大输入图，以控制输出形状的减少量

一般情况下：
如果步长为1，填充$p_h$行和$p_w$列，输入特征图的形状为$(n_h\times n_w)$，卷积核的形状为$(k_h\times k_w)$，则应用一次卷积，输出特征图形状为$(n_h - k_h + p_h + 1) \times (n_w - k_w +p_w + 1)$

通常我们取$p_h = k_h -1, p_w = k_w -1$(这样子选取主要是为了计算方便)，则输出特征图的形状为$(n_h,n_w)$，即形状不变
如果$k_h$为奇数，则$k_h-1$为偶数，在输入的上下两侧分别填充$(k_h - 1)/2$行，即$p_h/2$行即可
如果$k_h$为偶数(一般较少使用宽和高为偶数的卷积核)，则$k_h-1$为奇数，则一般在输入的上侧填充$\left\lceil{(k_h - 1)/2}\right\rceil$行，即$\left\lceil p_h/2\right\rceil$行，在输入的下侧填充$\left\lfloor (k_h-1)/2\right\rfloor$行，即$\left\lfloor p_h/2\right\rfloor$行，反过来也可
$k_w$同理

填充用于输入图比较小，希望增加网络深度的时候
### 2.3.2 步幅(stride)
如果对于一个相对较大的输入图像，例如(224, 224)，在使用(5, 5)的卷积核，保持步幅为1，填充为0，想要得到(4, 4)形状的输出特征图，需要经过55层，
需要大量的计算才可以得到较小的输出

层数过多会需要大量的计算，可以选用较大的卷积核来加速形状的减小，但一般我们不会使用过大的卷积核

保持步幅为1，输出特征图的大小是和层数线性相关的
(比如$4像素 = 224像素 - 55层\times 4像素/层$)

如果增加步幅，可以在相同卷积核大小，相同输入图像大小的情况下，使得输出图像的形状更小(成倍减少输出形状)

步幅是指每次卷积核在行/列上的滑动步长
比如高度3，宽度2的步幅，即每次往右边移动时，移动两列，每次往下面移动时，移动三行
如果原图像/添加了填充的图像剩下的行数/列数不够移动了，可以直接丢弃

一般情况下：
如果步幅的高度是$s_h$，宽度是$s_w$，填充$p_h$行和$p_w$列，输入特征图的形状为$(n_h\times n_w)$，卷积核的形状为$(k_h\times k_w)$，则应用一次卷积，输出特征图形状为$\lfloor(n_h - k_h + p_h + s_h)/s_h\rfloor \times \lfloor(n_w - k_w +p_w + s_w)/s_w\rfloor$，也可以写成$\left(\lfloor(n_h - k_h + p_h)/s_h\rfloor + 1\right) \times \left(\lfloor(n_w - k_w +p_w)/s_w\rfloor+1\right)$，取底就是默认当剩下的行数/列数不够移动了，直接丢弃

一般我们选择$p_h = k_h-1,p_w = k_w -1$，则输出图的形状为$\lfloor(n_h + s_h - 1)/s_h\rfloor \times \lfloor(n_w + s_w - 1)/s_w\rfloor$，即$\left(\lfloor(n_h - 1)/s_h\rfloor + 1\right) \times \left(\lfloor(n_w - 1)/s_w\rfloor+1\right)$
一般来说，如果输入图的高和宽都可以被步幅整除的话，则容易计算得到$\lfloor(n_h + s_h - 1)/s_h\rfloor \times \lfloor(n_w + s_w - 1)/s_w\rfloor = (n_h/s_h)\times (n_w/s_w)$

一般取步幅都为2，如果输入图的宽和高都为偶数的话，输出图的宽和高就是输入图的二分之一

步幅用于输入图比较大，希望减少网络深度以减少计算量的时候，步幅这个参数的主要意义是减少计算量

### 2.3.3 Pytorch中的填充和步幅
```python
def comp_conv2d(conv2d, X):
	X = X.reshape((1,1) + X.shape) # 将形状从(W, H)变为(B, C, W, H)
	Y = conv2d(X)
	return Y.reshape(Y.shape[2:]) # 去掉前面两个维度

# 填充相同的高度和宽度
conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1) # 上下左右各填充1行/1列，即p_h = p_w = 2
X = torch.rand(size=(8, 8))
comp_conv2d(conv2d, X).shape

out: torch.Size([8, 8])

# 填充不同的高度和宽度
conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1)) # p_h = 4, p_w = 2
comp_conv2d(conv2d, X).shape

out: torch.Size([8, 8])

# 设置s_w = s_h = 2
conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)
comp_conv2d(conv2d, X).shape

out: torch.Size([4, 4])

# p_h = 0, p_w = 1, s_h = 3, s_w = 4
conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))
comp_conv2d(conv2d, X).shape

out: torch.Size([2, 2])
```

### 2.3.4 通道(channel)
彩色图像有RGB三个通道
灰度图只有一个通道

**多通道输入，单通道输出**
对多通道的图像做卷积操作时，图像的每个通道都有自己的卷积核，卷积操作时，图像的通道和各自相应的卷积核做卷积，可以得到$C$个数($C$为通道数)，再将它们相加即可，即对于输入$\mathbf X(c_i\times n_h\times n_w)$，卷积核$\mathbf W(c_i\times k_h\times k_w)$
输出：$$\mathbf Y(m_h\times m_w) = \sum_{i=0}^{c_i}\mathbf X_{i,:,:}\star \mathbf W_{i,:,:}$$(这里忽略了偏移，实际中每个通道都有自己的偏移，图像整体的偏移是一个长度为$c_i$的向量)

可以发现，对于多通道的图像，输入是一个三维张量，卷积核也是一个三维张量，而输出则是二维张量，也就是说而对多个输入通道的图像做卷积操作，输出特征图是单通道的

**多通道输入，多通道输出**
如果需要多个输出通道，则对于每一个输出通道，都需要一个三维卷积核，因此需要多个三维卷积核，每个三维卷积核生成一个输出通道，即对于输入$\mathbf X(c_i\times n_h\times n_w)$，卷积核$\mathbf W(c_0\times c_i\times k_h\times k_w)$
输出$\mathbf Y(c_o\times m_h\times m_w)$，其中：
$$\mathbf Y_{i,:,:} = \sum_{i=0}^{c_i}\mathbf X\star \mathbf W_{i,:,:}\quad for\ i=1,\cdots,c_0$$

可以发现，对于多通道的图像，输入是三维张量，卷积核是四维张量，则输出则是三维张量，即得到多通道的输出特征图

为什么需要多个输出通道、为什么每个输出通道都有各自的核(三维的)：
每一个输出通道可以识别特定的模式
为什么需要多个输入通道、为什么每个输入通道都有各自的核(二维的)：
输入通道中，每个通道有各自特定的模式(前一层的输出通道就是后一层的输入通道)，借助不同的核，对这些模式进行识别，并进行组合(乘上权重相加)

$1\times 1$卷积层：
卷积核的高和宽都是1($k_w = k_h = 1$)
因为只看一个像素，不涉及周围，因此它不识别(单个通道内的)空间模式，但是它可以用于融合通道信息
因为不涉及空间信息，做$1\times 1$卷积，等价于先把形状为$c_i\times n_h\times n_w$三维输入张量拉成形状为$n_hn_w\times c_i$的二维输入张量，然后乘上一个形状为$c_i\times c_o$的权重矩阵，即全连接

**二维卷积、二维卷积层**
输入$\mathbf X(c_i\times n_h\times n_w)$，卷积核$\mathbf W(c_0\times c_i\times k_h\times k_w)$，偏差$\mathbf B(c_o\times c_i)$
输出$\mathbf Y(c_0\times m_h\times m_w) = \mathbf X\star\mathbf W + \mathbf B$

计算复杂度(浮点计算次数FLOP)：
$O(c_oc_ik_hk_wm_hm_w)$(对于每一个输出的像素，都需要$c_ik_hk_w$次的计算，而一共会输出$c_om_hm_w$个像素)

若$c_i=c_o=100,k_h=k_w=5,m_h=m_w=64$，则需要1GFLOP(10亿次)
若有10层这样的卷积层，有1M个样本(ImageNet)，则需要10PFLOP(注意仅仅是前向运算)
对于一个0.15TFs的CPU，需要18h，对于一个12TFs的GPU，需要14min(注意仅仅是前向运算一次)

## 2.4 池化层
卷积层对位置是十分敏感的
例如，我们想要检测

$$X = \begin{bmatrix}
1. & 1. & 0. & 0. & 0.\\ 
1. & 1. & 0. & 0. & 0.\\
1. & 1. & 0. & 0. & 0.\\
1. & 1. & 0. & 0. & 0.\\
\end{bmatrix}$$

中的垂直边缘，因此我们应用一个 $1\times 2$ 的卷积核 $[1.0 , -1.0]$，卷积后得到

$$Y = \begin{bmatrix}
0. & 1. & 0. & 0. \\ 
0. & 1. & 0. & 0. \\
0. & 1. & 0. & 0. \\
0. & 1. & 0. & 0. \\
\end{bmatrix}$$

如果图像 $X$ 整体向左偏移一个像素，卷积核不变，很显然卷积输出 $Y$ 中的检测到的边缘也将整体向左偏移一个像素，即

$$Y_{left} = \begin{bmatrix}
1. & 0. & 0. & 0. \\ 
1. & 0. & 0. & 0. \\
1. & 0. & 0. & 0. \\
1. & 0. & 0. & 0. \\
\end{bmatrix}\neq Y$$

可以发现$Y_{left}$相较于$Y$，有两列的值是不同的

在实际情况中，即使是相机连续拍摄的图像中，图像中物体也不可能完全保持在原来的像素位置不变，相机的抖动、物体的抖动、光线的变化等都会导致图像之间会有细微的偏移
因此我们需要一定程度的平移不变性，即使图像有像素级的细微偏移，也不会导致输出有大的改变
池化层用于缓解卷积层对位置的敏感性，也可减少计算量

**二维最大池化**
例如有输入$$input = \begin{bmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9\\
\end{bmatrix}$$
对它进行$2\times 2$最大池化(步长为1)，得到输出$$output=\begin{bmatrix}
5 &6\\
8 & 9\\
\end{bmatrix}$$池化层和卷积层一样，在输入上滑动窗口得到输出，最大池化会返回窗口内的最大值

对于之前的例子，在卷积过后如果再对$Y$进行$2\times 2$最大池化(步长为2)，得到$$Z = \begin{bmatrix}
1. & 0.\\
1. & 0. \\
\end{bmatrix}$$我们对$$Y_{left} = \begin{bmatrix}
1. & 0. & 0. & 0. \\ 
1. & 0. & 0. & 0. \\
1. & 0. & 0. & 0. \\
1. & 0. & 0. & 0. \\
\end{bmatrix}$$也进行$2\times 2$最大池化(步长为2)，得到$$Z_{left}=\begin{bmatrix}
1. & 0.\\
1. & 0.\\
\end{bmatrix}=Z$$因此$2\times 2$的最大池化操作容忍了向左的1像素偏移，因为偏移后输出也没有改变

池化层和卷积层一样，也有窗口形状、填充、步幅作为超参数(PyTorch中，默认步幅大小与窗口长度是相同的)
池化层与卷积层不同的是池化层中没有可学习的参数
对多输入通道进行池化操作时，池化层逐通道进行操作，与卷积层不同的是它不会融合多个通道，一定满足输入通道数=输出通道数(融合通道信息的工作仅由卷积层完成)
 
**二维平均池化**
最大池化输出窗口内数据的最大值(窗口内最强的模式信号)，因此得到的输出会有较为明显的层次化信息
与最大池化不同，平均池化输出窗口内数据的平均值，因此得到的输出的信号强度会弱很多(均值永远小于等于最大值)，会起到平滑和柔和化的效果，减小抖动和区分性

对数据本身做旋转等增强操作，可以让卷积层不容易对具体位置过拟合，以淡化池化层的作用
池化层减少计算量的作用也可以通过令卷积层的步长大于1替代

## 2.5 卷积神经网络 LeNet
### 2.5.1 LeNet介绍
LeNet在80年代主要用于手写数字识别

**MNIST**
50000个训练图像
10000个测试图像
图像大小$28\times 28$，灰度图
10类(数字0到9)

**LeNet**
LeNet接收$28\times 28$的单通道输入图像
第一层：卷积层
卷积核$5\times 5$，步长1，填充$4\times 4$，输入通道数1，输出通道数6
输入形状$(1, 28, 28)$
输出形状$(6, 28 , 28)$

第二层：池化层
核$2\times 2$，步长2，填充0
输入形状$(6, 28, 28)$
输出形状$(6, 14, 14)$

第三层：卷积层
卷积核$5\times 5$，步长1，填充0，输入通道数6，输出通道数16
输入形状$(6, 14, 14)$
输出形状$(16, 10 , 10)$

第四层：池化层
核$2\times 2$，步长2，填充0
输入形状$(16, 10 , 10)$
输出形状$(16, 5 , 5)$

第五层：全连接层
输入形状$(1, 400)$
输出维度$(1, 120)$

第五层：全连接层
输入形状$(1, 120)$
输出维度$(1, 84)$

第六层：全连接层
输入形状$(1, 84)$
输出维度$(1, 10)$
然后做Softmax得到概率

LeNet是早期成功的神经网络，它先使用卷积层学习图片的空间信息，然后使用全连接层将信息转换到类别空间
LeNet中，卷积层将特征图变小，但通道数增加，每个通道的信息就是图像中的空间模式(pattern)，卷积层将图像中的这类空间信息压缩，存储在不同的通道中，因此经过卷积层，特征图大小减小，通道数增加，最后全连接层将所有通道中所有的模式压缩到输出，这就是LeNet的设计思想，也是大部分CNN的设计思想

卷积神经网络相较于全连接网络，因为卷积层的极大减少了参数量，模型的复杂度也因此降低，因此过拟合的概率也会小于单纯的全连接网络
### 2.5.2 PyTorch实现
```python
class Reshape(torch.nn.Module):
	def forward(self, x):
		return x.view(-1, 1, 28, 28)

net = torch.nn.Sequential(
	Reshape(),
	nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),
	nn.AvgPool2d(kernel_size=2, stride=2),
	nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),
	nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),
	nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),
	nn.Linear(120, 84), nn.Sigmoid(),
	nn.Linear(84, 10)
)

X = torch.rand(size=(1, 1, 28, 28), dtype=torhc.float32)
for layer in net:
	X = layer(x)
	print(layer.__class__.__name__, 'output shape: \t', X.shape)
```

## 2.6 深度卷积神经网络 AlexNet
### 2.6.1 AlexNet介绍
大数据集的出现促使了更深的神经网络的出现
**ImageNet-ILSVRC(2010)**
120万个图像
图像大小$469\times 387$，彩色图
1000类

**AlexNet**
AlexNet赢得了2012年的ImageNet竞赛
AlexNet本质上就是一个更大更深的LeNet，但相较于LeNet有三点改进
- 层内采用了丢弃法(dropout)
- 激活函数采用了ReLu
- 池化层采用了MaxPooling
AlexNet改变了计算机视觉的方法论，
在AlexNet之前，CV研究者关注的是如何做人工特征提取(如SIFT)，而非后续的分类模型(当时普遍采用SVM)，而在AlexNet之后，CV研究者关注的是如何利用CNN提取特征，分类直接交给模型的最后一层Softmax回归，
特征提取阶段和分类阶段从相互独立到一起训练(端到端)，这显然更加高效和协调

AlexNet架构
AlexNet接收$224\times 224$的三通道输入图像

第一层：卷积层
卷积核$11\times 11$，步长4，输入通道数3，输出通道数96
因为接收图片更大了，因此AlexNet的卷积核/图片窗口大小也相较于LeNet更大了
为了在第一层就识别出图片中尽可能多的模式，输出通道数也非常多
步长为4是为了减少计算量

第二层：池化层
核$3\times 3$，步长2
相较于LeNet，池化窗口变大了，以提供更多的位置稳定性(允许图像向左或右移动一像素)
相较于LeNet，采用的非平均池化，而是最大池化

之后的层数中，卷积层普遍采用了更多的输出通道，为了识别更多的模式，
相较于LeNet，AlexNet增加了三层连续的卷积层
最后的全连接层中，隐藏层维度也更大，达到了4096维

AlexNet中，激活函数从Sigmoid换成了ReLu，缓解了梯度消失的问题，因为ReLu函数保持了较大的值(Sigmoid则是进行了压缩)，因此也保持了较大的梯度值
AlexNet在全连接层的隐藏层内加入了dropout层以实现正则化
AlexNet的另外重要一点是做了数据增强

在模型复杂度上，AlexNet的可学习参数个数在LeNet的10倍以上
在计算复杂度上，AlexNet前向传播一次的计算次数是LeNet的250倍

### 2.6.2 PyTorch实现
```python
net = nn.Sequential(
	nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1),
	nn.ReLU(),
	nn.MaxPool2d(kernel_size=3, stride=2),
	nn.Conv2d(96, 256, kernel_size=5, padding=2),
	nn.ReLU(),
	nn.MaxPool2d(kernel_size=3, stride=2),
	nn.Conv2d(256, 384, kernel_size=3, padding=1),
	nn.ReLU(),
	nn.Conv2d(384, 384, kernel_sze=3, padding=1),
	nn.ReLU(),
	nn.Conv2d(384, 256, kernel_size=3, padding=1),
	nn.ReLU(),
	nn.MaxPool2d(kernel_size=3, stride=2),
	nn.Flatten(),
	nn.Linear(6400, 4096),
	nn.ReLU(),
	nn.Dropout(p=0.5),
	nn.Linear(4096, 4096),
	nn.ReLU(),
	nn.Dropout(p=0.5),
	nn.Linear(4096, 1000)
)
```

## 2.7 使用块的网络 VGG
### 2.7.1 VGG介绍
VGG的思路来自于既然AlexNet比LeNet更深更大就得到了更好的精度，那么可以尝试实现比AlexNet更深更大的网络

VGG提出了块的概念
一个VGG块内有$n$个$3\times 3$大小，填充为$1$的卷积层，保持输入输出通道都为$m$个不变，块的最后是一个$2\times2$，步幅为$2$的池化层

VGG的架构就是$n$个VGG块串联，最后接上全连接层
块的重复次数决定了VGG的深度，因此得到不同的VGG变体，如VGG-16、VGG-19

总结：
VGG使用可重复使用的卷积块来构建深度卷积神经网络
不同卷积块个数和超参数可以得到不同复杂度的变种

### 2.7.2 Pytorch实现
```python
def vgg_block(num_convs, in_channels, out_channels):
	layers = []
	for _ in range(num_convs):
		layers.append(nn.Conv2d(
			in_channels, out_channels, kernel_size=3, padding=1))
		layers.append(nn.ReLU())
		in_channels = out_channels
	layers.append(nn.MaxPool2d(kernel_size=2, stride=2))
	return nn.Sequential(*layers)

conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512)) # (num_convs, num_channels), len of list = num_blocks

def vgg(conv_arch):
	conv_blks = []
	in_channels = 1
	for (num_convs, out_channels) in conv_arch:
		conv_blks.append(vgg_block(
			num_convs, in_channels, out_channels))
		in_channels = out_channels

	return nn.Sequential(
		*conv_blks, nn.Flatten(),
		nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(),
		nn.Dropout(0.5), nn.Linear(4096, 4096), nn.ReLU(),
		nn.Dropout(0.5), nn.Linera(4096, 10))
```

## 2.8 网络中的网络 NiN
### 2.8.1 NiN介绍
AlexNet和VGG中都在最后使用了较大的全连接层，而全连接层的缺陷在于其过于昂贵且容易过拟合

卷积层的参数量为$c_i \times c_o \times k^2$(输入通道$\times$输出通道$\times$窗口大小)
而全连接层的参数量为输入像素(输入通道$\times$输入高度$\times$输入宽度)$\times$输出像素(输出通道$\times$输出高度$\times$输出宽度)

NiN的思想是用卷积层替代全连接层

NiN块：一个卷积层后跟两个$1\times 1$卷积层(步幅为$1$，无填充，通道数不变)，这两个$1\times1$卷积层起到之前网络中全连接层的作用，用于混合通道信息

NiN架构：交替使用NiN块和步幅为$2$的最大池化层(用于逐渐减小高宽和逐渐增大通道数)，最后使用全局平均池化层(即池化窗口就是整个输入图像)得到输出(其输入通道数为类别数，因此等价于取出每个通道的平均值)，整个网络架构中没有全连接层

总结：
NiN块使用卷积层加两个$1\times1$卷积层，后者对每个像素增加了非线性性
NiN使用全局平均池化层来替代VGG和AlexNet中的全连接层，因此不容易过拟合，并且参数个数更少(池化层不需要参数)

### 2.8.1 Pytorch实现
```python
def nin_block(in_channels, out_channels, kernel_size, strides, padding):
	return nn.Sequential(
		nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding), nn.ReLU(),
		nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(),
		nn.Conv2d(out_channels, out_channels, kernal_size=1), nn.ReLU())

net = nn.Sequential(
	nin_block(1, 96, kernel_size=11, stride=4, padding=4),
	nn.MaxPool2d(3, stride=2),
	nin_block(96, 256, kernel_size=5, stride=1, padding=2),
	nn.MaxPool2d(3, stride=2),
	nin_block(256, 384, kernel_size=3, stride=1, padding=1),
	nn.MaxPool2d(3, stride=2), 
	nin_block(384, 10, kernel_size=3, stride=1, padding=1),
	nn.AdaptiveAvgPool2d((1,1)),
	nn.Flatten())
```
## 2.9 含并行连接的网络 GoogLeNet
### 2.9.1 GoogLeNet介绍
GoogLeNet的创新点在于Inception块
Inception块中有四条计算路径，
第一条路径是一个$1\times 1$的卷积层
第二条路径是一个$1\times 1$的卷积层(融合通道信息)和一个$3\times 3$，填充为1的卷积层(保持输出形状与输入相同)
第二条路径是一个$1\times 1$的卷积层(融合通道信息)和一个$3\times 3$，填充为2的卷积层(保持输出形状与输入相同)
第二条路径是一个$3\times 3$，填充为1的最大池化层，和一个$1\times 1$的卷积层

四条路径都保持了输入和输出的高宽相同，Inception块在最后对这四条路径的输出在通道维度上进行合并
Inception借助四条路径在四个层面抽取信息，然后在输出通道维度合并

GoogLeNet中，第一个Inception块接收(28, 28, 192)的输入
第一条路径输出通道数64
第二条路径第一层输出通道数96(将通道数进行压缩，以降低模型复杂度，因为这一层的输出通道数与下一层卷积层的参数数量有关)，第二层输出通道数128
第三条路径第一层输出通道数16(将通道数进行压缩，以降低模型复杂度，因为这一层的输出通道数与下一层卷积层的参数数量有关)，第二层输出通道数32
第二条路径第一层池化层不改变通道数，第二层输出通道数为32

可以发现，第二、三、四条路径的$1\times 1$卷积的目的主要在于改变通道数(降低模型复杂度)，而第二、三条路径的$3\times 3, 5\times 5$卷积，第一条路径的$1\times 1$卷积层目的则在于提取信息，其中第一条路径仅提取通道信息，第二、三条路径提取通道信息和空间信息，当然最大池化也会提取空间信息

第一个Inception块的输出通道数是256，我们考虑以下作者通道数的设计思路：
我们知道我们需要的是每个通道识别图片中某个模式，因此我们需要为重要的网络结构分配更多的通道数，作者为$3\times 3$卷积层分配了128个通道，因为从经验上看，$3\times 3$卷积层计算量不大，且能有效提取信息(空间信息+通道信息)，为第一条路的$1\times 1$卷积分配了64个通道，以提取通道信息，剩下的平分给第三、四条路

保持输入输出形状不变，在要求同样的输出通道数的情况下，使用Inception块比全部使用$3\times 3$或$5 \times 5$卷积层所需要的参数数量要少许多，因此计算复杂度也更低

可以认为Inception块在增加了计算多样性的同时降低了计算复杂度

GoogLeNet有5阶段(stage)，共9个Inception块，最后一个全连接层
(所谓阶段即输入的高宽减半为1个阶段)
Inception块集中于后三个阶段

GooLeNet接收(224, 224, 3)的输入，经过阶段1和2，输出为(28, 28, 192)，因此阶段1和2的主要目的就是减少图像大小，增大通道数量
GooLeNet的第三个阶段接收(28, 28, 192)的输入，输出为(14, 14, 480)，该阶段有两个Inception块，两个块内部的通道数分配有所不同
GooLeNet第四个阶段有5个Inception块，第五阶段有两个Inception块，最后经过全局平均池化，得到$1024\times 1\times 1$的输出，可以认为是输入图片最终的特征向量

目前介绍的是V1版本的Inception，后续有许多变种，例如
Inception-BN(V2)，加入了batch normalization
Inception-V3，在V2基础上，修改了Inception块
- 替换$5\times 5$为多个$3\times 3$卷积层
- 替换$5\times 5$为$7\times 1$和$1\times 7$卷积层
- 替换$3\times 3$为$1\times 3$和$3\times 1$卷积层
- 更深
Inception-V4，使用残差连接

Inception-V3已经完全超越VGG，在ImageNet上的准确率可以达到0.8

总结：
Inception块有四条不同超参数的卷积层和池化层的路来抽取不同的信息，它的主要优点在于模型参数少，计算复杂度不高
GooLeNet使用了9个Inception块，是第一个达到上百层的卷积神经网络(不是纯深度达到了100层，深度的拓展要等到ResNet的出现)
### 2.9.2 Pytorch实现
```python
class Inception(nn.Module):
	def __init__(self, in_channels, c1, c2, c3, c4, **kwargs):
		super(Inception, self).__init__(**kwargs)
		self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)
		self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)
		self.p2_2 = nn.Conv2d(c2[0], c[1], kernel_size=3, padding=1)
		self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)
		self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=1)
		self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)
		self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)

	def forward(self, x):
		p1 = F.relu(self.p1_1(x))
		p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))
		p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))
		p4 = F.relu(self.p4_2(self.p4_1(x)))
		return torch.cat((p1, p2, p3, p4), dim=1)
```
## 2.10 批量规范化 BatchNorm
### 2.10.1 BatchNorm介绍
较深的网络存在梯度消失的问题，往往上面的层的梯度较大，训练较快，但底部的层的梯度一般来源于多个很小的数相乘，训练较慢
因此，上面的层的收敛速度往往较快，下面的层收敛较慢

一般来说，下面的层负责抽取较于底层的信息，例如局部的纹理、边缘等，上面的层负责处理高层次的抽象信息，因此还有一个问题就是当底层发生了变化，上层往往要随之变化，甚至等同于重新训练，因此最后的一些层甚至要重新学习多次

综合两个问题，我们知道在训练进行的过程中，底部的层在缓慢变化，顶部的层在快速变化，且底部的层变化后，顶部的层时常要重新训练，以拟合底部变化导致的问题，最终导致收敛变慢

批量规范化考虑的问题就是如何在学习底部层的时候避免变化顶部层
训练过程中，方差和均值的分布会随着层数的变化而变化/偏移，批量规范化化希望固定住分布，即每一层的输出、梯度都服从同一个分布，此时整个网络相对来说是比较稳定的(数据稳定性)

批量规范化尝试固定每一层的小批量(minibatch)的输出的方差和均值
小批量的均值和方差的计算如下
$$\mu_B = \frac 1 {|B|}\sum_{i\in B}x_i, \sigma_B^2 = \frac 1 {|B|}\sum_{i\in B}(x_i-\mu_B)^2+\epsilon$$
计算出均值和方差后，对每个小批量内的样本做以下处理
$$x_{i+1}=\gamma\frac {x_i-\mu_B}{\sigma_B}+\beta$$
其中$\gamma,\beta$是可以学习的参数，意图在于假如做了归一化后，分布依旧不太适合，则可以通过学习，$\gamma$改变方差，$\beta$改变均值以利于训练，当然$\gamma,\beta$的值的变化会限定范围

对数据进行批量规范化计算，可以抽象出一层网络中的批量规范化层，它的可学习的参数是$\gamma,\beta$，
一般该层作用在全连接层/卷积层的输出上，激活函数之前，(注意BN是一个线性变换，激活函数是非线性的)
也可以作用在全连接/卷积层的输入上
对于全连接层，批量规范化针对特征维，即依次每一维度的特征进行批量规范化(注意我们在进行数据预处理时也常常这么做，这里不一样的在于我们对网络内每一个全连接层的输入输出也这么做)
对于卷积层，批量规范化针对通道维(我们可以把多通道图片也视为二维的数据，每个像素就是一个样本，每一行代表每一个像素的特征，通道就是特征维度，每个通道都表示了该像素在具体的特征维度下的取值；因此$1\times 1$卷积实际上也可以视为全连接，它对每一个像素/样本都做同样的事情，每个通道/特征维度都乘上同样的权重)

批量规范化最初被提出时，作者认为它的作用在于减少内部协变量的转移(协变量转移简单理解就是数据的分布发生变化，用变化前的分布训练的模型就失效了，内部协变量转移就是说数据在经过每一层的计算后，它的分布逐渐发生了偏移)
但后续的论文指出BN并没有对减少内部协变量的转移起到作用，而是在每一个小批量里加入了噪音，以控制模型复杂度，
BN层的计算如下
$$x_{i+1} = \gamma\frac {x_i - \hat \mu_B}{\hat \sigma_B}+\beta$$
而噪音来自于$\hat \mu_B$和$\hat \sigma_B$，其中$\hat \mu_B$是随机偏移，$\hat \sigma_B$是随机缩放
因为每一个小批量都是随机选取的，因此统计量$\hat \mu_B$，$\hat \sigma_B$也带有随机性，因此认为它自身带有的噪声是比较大的，而对数据做了这样的处理，就可以认为是对数据做了随机的一些均值转移和方差缩放
而$\gamma,\beta$由于是可学习的参数，变化由学习率控制，因此它们的变化不会很剧烈
也就是说BN的作用在于首先对数据引入随机性，即随机偏移和随机缩放，但同时也通过学习到的均值和方差使得数据保持稳定性，因此数据中保留了一定的随机性，但不会剧烈变化
因此认为BN是在每一个小批量里加入了噪音，以控制模型复杂度

从这个角度出发，如果BN就是一个用于控制模型复杂度的办法，那就没必要和dropout一起使用了

总结：
批量归一化尝试固定小批量中样本的均值和方差，然后学习出适合的偏移和缩放
批量归一化可以加快收敛速度(用了BN后可以用更大的学习率，直观理解就是数据的分布稳定后，上面的层和下面的层可以用统一的学习率了，不会因为学习率太大导致上面的层收敛太快然后越过最低点，也不会因为学习率太小导致下面的层根本不移动)，但一般不改变模型精度(也就是加了BN也一般不会让模型更好)
### 2.10.2 Python实现
```python
def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):
	# 推理而不是训练时
	if not torch.is_grad_enabled():
		X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)
	# 训练时
	else:
		assert len(X.shape) in (2, 4) 
		# X维度为2时就是全连接层，一个维度是批量维度，一个维度是特征维度，X维度为4时就是卷积层，第一个维度是批量维度，第二个维度是通道维度，最后两个维度就是图片高宽
		if len(X.shape) == 2:
			# 按特征求均值方差
			mean = X.mean(dim=0)
			var = ((X - mean)**2).mean(dim=0)
		else:
			# 按通道求均值方差
			mean = X.mean(dim=(0, 2, 3), keepdim=True)
			var = ((X - mean)**2).mean(dim=(0, 2, 3), keepdim=True)
		X_hat = (X - mean) / torch.sqrt(var + eps)
		moving_mean = momentum * moving_mean + (1 - momentum) * mean
		moving_var = momentum * moving_var + (1 - momentum) * var
	Y = gamma * X_hat + bata
	return Y, moving_mean, moving_var
```
其中 `moving_mean` , `moving_var` 可以认为是我们所控制的全局的均值和方差
```python
class BatchNorm(nn.Module):
	def __init__(self, num_features, num_dims):
		super().__init__()
		if num_dims == 2:
			shape = (num_features, num_dims)
		else:
			shape = (1, num_features, 1, 1)
		self.gamma = nn.Parameter(torch.ones(shape))
		self.beta = nn.Parameter(torch.zeros(shape))
		self.moving_mean = torch.zeros(shape)
		self.moving_var = torch.ones(shape)

	def foward(self, X):
		if self.moving_mean.device != X.device:
			self.moving_mean = self.moving_mean.to(X.device)
			self.moving_var = self.moving_var.to(X.device)
		Y, self.moving_mean, self.moving_var = batchnorm(X, self.gamma, self.beta, self.moving_mean, self.moving_var, eps=1e-5, momentum=0.9)
		return Y
```
## 2.11 残差网络 ResNet
### 2.11.1 ResNet介绍
ResNet的思路就在于往网络上加更多的层，即使效果不会变好，但至少要保持不会变差

ResNet的主要结构是残差块
因为ResNet意图在于添加新层时，保持效果至少不会变差，我们如果之间简单在原来的网络上叠加新的层，它可能会改变原来的函数类，而我们希望不是直接改变原来的函数类，而是在原来函数类的基础上扩大函数类
因此得到残差块的结构，它的函数形式为$f(x) = x + g(x)$，其中$x$是原来的函数类，$g(x)$是叠加的新层的函数类，$f(x)$的形式就是在原来的函数类$x$的基础上加上$g(x)$的扩大的函数类
在训练时，如果$g(x)$对损失的下降没有太多贡献，就不会拿到太多的梯度，甚至梯度变为0，因此它的权重就几乎不会更新，保持为很小的权重，或者权重逐渐变小，最后使得$g(x)$对模型没有什么影响

ResNet总体架构和VGG类似，有两种类型的残差块：
将输入图高宽减半且通道数翻倍的残差块和保持输入输出形状的残差块，
网络中一般是一个改变形状的残差块后接多个保持形状的残差块作为一个阶段(stage)
一共五个阶段

总结：
残差块使得很深的网络更加容易训练
残差连接的思想被之后的深度神经网络广泛采用
### 2.11.2 Pytorch实现
```python
class Residual(nn.Module):
	def __init__(self, input_channels, num_channels, use_1x1conv=False, strides=1):
		super().__init__()
		self.conv1 = nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1, stride=strides)
		self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=3, paddding=1)
		if use_1x1conv:
			self.conv3 = nn.Conv2d(input_channels, num_channels, kernel_size=1, stride=strides)
		else:
			self.conv3 = None
		self.bn1 = nn.BatchNorm2d(num_channels)
		self.bn2 = nn.BatchNorm2d(num_channels)
		self.relu = nn.ReLU(inplace=True)

	def forward(self, X):
		Y = self.relu(self.bn1(self.conv1(X)))
		Y = self.bn2(self.conv2(Y))
		if self.conv3:
			X = self.conv3(X)
		Y += X
		return self.relu(Y)
```
### 2.11.3 残差连接与梯度消失
有模型$y = f(x)$，有一个层的参数$w$
那么我们有梯度$\frac {\partial y}{\partial w}$
每一次的参数更新，我们做$w = w - \eta \frac {\partial y}{\partial w}$
我们希望$\frac {\partial y}{\partial w}$不要太小，否则参数难以更新

此时我们在原有模型的基础上再叠加一些层，得到$y' = g(f(x))$
那么我们有梯度$\frac {\partial y'}{\partial w} = \frac {\partial y'}{\partial y}\frac {\partial y}{\partial x}=\frac {\partial g(y)}{\partial y}\frac {\partial y}{\partial x}$
可以看到多乘了一项$\frac {\partial g(y)}{\partial y}$，即新加的层的输出相对输入的偏导数
如果新加入的层是有较强性能的模型，那么它的输出相对输入的导数就会相对较小(误差小梯度就小)，导致$\frac {\partial g(y)}{\partial y}\frac {\partial y}{\partial x}$，即底层的梯度消失

考虑在叠加的基础上引入一条残差连接，得到$y'' = y + y' = f(x) + g(f(x))$
那么我们有梯度$\frac {\partial y'}{\partial w} = \frac {\partial y'}{\partial y}\frac {\partial y}{\partial x} + \frac {\partial y}{\partial x}$
因为额外加了一项$\frac {\partial y}{\partial x}$，梯度消失的问题就得到有效缓解
# 3 计算机视觉
## 3.1 硬件介绍
### 3.1.1 CPU和GPU
如何提升CPU利用率
考虑我们要计算$a+b$，在计算之前，我们需要准备数据，具体为：
将数据从内存运到L3缓存，然后运到L2缓存，然后运到L1缓存，最后运到寄存器
寄存器的访问频率可以认为和CPU主频一致
L1缓存的访问延时一般为0.5ns
L2缓存的访问延时一般为7ns(14倍L1)
内存的访问延时一般为100ns(200倍L1)

为了提升性能，需要考虑提升空间和时间的内存本地性
时间：提高对缓存内的数据重用
空间：尽量按序读取数据，提高预读取的命中率

CPU一般是多核的，多利用并行也可以提高CPU利用率
注意超线程技术不一定提升性能，因为寄存器是共享的

GPU的核心数量和内存带宽都远高于CPU，但正因显存的带宽要高于一般内存，显存的价格也相对昂贵，导致GPU显存大小会远小于CPU内存大小

CPU处理控制流的能力远远强于GPU，CPU核心内有大量的逻辑单元，甚至多于计算单元，而GPU的芯片面积几乎全用于计算单元

如何提升GPU利用率
并行，利用好大量的线程
内存本地性，GPU核心的缓存很小，架构也更简单，因此也要利用好内存本地性
少用控制语句，GPU对控制语句的支持有限，遇到控制语句会产生很大的同步开销，导致大量核心停滞

由于CPU和GPU之间的PCIE带宽受限，且存在同步开销，因此也不要频繁在GPU和CPU之间传递数据

总结：
CPU可以处理通用计算，性能优化考虑数据读写效率和多线程
GPU使用更多的小核和更好的内存带宽，适合能大规模并行计算任务
### 3.1.2 更多的专有硬件
**DSP(Digital Signal Processor)数字信号处理器**
DSP最早是为数字信号处理算法而设计的，处理的运算一般是点积、卷积和FFT
DSP的特点是低功耗，高性能，DSP为了降低功耗，核心数量不多，频率也不高，它的高性能来源于VLIW(Very Long Instruction Word)，即非常长的指令字，DSP的一条指令可以计算上百次的乘累加
DSP目前的使用不太广泛，原因在于在DSP上编程和调试很困难，工具链不完善，编译器质量良莠不齐(对硬件来说，编译器的性能是异常重要的)

**FPGA(Field Programmable Gate Array)可编程门阵列**
FPGA由大量的可以编程的逻辑单元和可配置的连接构成
FPGA上的编程语言一般用VHDL或Verilog
FPGA的执行效率通常比通用硬件(CPU)更高效，高端的FPGA理论上性能可以优于GPU
FPGA的缺点在于其工具链质量良莠不齐，一次“编译”需要数小时甚至几天(“编译”指将逻辑单元改变，重新烧写，涉及到硬件的改动)，同时语言也过于底层
FPGA常用于模拟，流片的成本非常高，不可能每一次完成一个设计方案就流一次片，设计好后，一般先用CPU模拟它的运行，之后，再在FPGA上烧出这个芯片，进一步模拟，如果在FPGA上的性能过关，再送去流片

**AI ASIC(Application Specific Integrated Circuit)AI特定芯片**
ASIC即针对某个应用做的特定的芯片
Intel，Qualcomm，Google，Amazon，Facebook等大公司都在造自己的芯片，大公司做自己的ASIC的原因在于便宜(不让Nvidia赚利润)，且因为硬件的针对性强，通用性弱，实际的设计门槛会低很多
其中Google的TPU芯片最为著名，TPU性能可以媲美Nvidia GPU，TPU在Google内部已经大量部署，TPU的核心是脉动阵列(systolic array)，专门用于大矩阵乘法
Systolic Array实际是一个计算单元阵列(Process Element Array)，阵列的形状对应矩阵乘法也设计成2D的形状，因此非常适合做矩阵乘法，且设计和制造也相对简单
## 3.2 单机多卡训练
### 3.2.1 单机多卡训练介绍
**单机多卡并行**
一台机器可以安装多个GPU(1-16个)
在训练和预测时，我们可以将一个小批量计算切分到多个GPU上来达到加速加速目的
常用的切分方案有
- 数据并行
- 模型并行
- 通道并行(数据+模型并行)

**数据并行vs模型并行**
数据并行：
将小批量分成n块，每个GPU拿到完整的参数，计算一小块小批量数据的梯度
每个GPU算完自己的一小块梯度，再全部加起来，就是整个小批量的梯度
数据并行的性能通常更好，因为数据分布相对均匀
模型并行：
将模型分成n块，每个GPU拿到一块模型计算它的前向和反向结果
例如100层的网络，每个GPU只负责其中20层，每个GPU都拿到完整的数据，计算的结果作为下一个GPU的输入
主要使用场景是模型过大导致单GPU的显存放不下

**总结**
当一个模型可以用单卡计算时(单卡存得下一整个模型的参数)，通常用数据并行拓展到多卡以加速计算
模型并行则用在超大模型上(单卡存不下一整个模型的参数)
### 3.2.2 Pytorch实现
```python
# 从CPU向GPU分发参数
def get_params(params: list, device):
	new_params = [p.clone().to(device) for p in params]
	for p in new_params:
		p.requires_grad_()
	return new_params

# allreduce函数将所有向量相加，并将结果广播给所有的GPU
def allreduce(data: list):
	# 所有GPU_0以外的GPU，把数据搬运到GPU_0，然后相加
	for i in range(1, len(data)):
		data[0][:] += data[i].to(data[0].device)
	# 把计算结果写回其他GPU
	for i in range(1, len(data)):
		data[i] = data[0].to(data[i].device)

# 将一个批量的数据均匀分布给多个GPU
devices: list = [torch.device('cuda:0'), torch.device('cuda:1')]
def split_batch(X, y, devices) -> tuple:
	assert X.shape[0] == y.shape[0]
	return (nn.parallel.scatter(X, devices), 
			nn.parallel.scatter(y, device))
			
# 在一个小批量上实现多GPU训练
def train_batch(X, y, device_params, devices, lr):
	X_shards, y_shards = split_batch(X, y, devices)
	ls = [loss(lenet(X_shard, device_W), y_shard).sum() 
		for X_shard, y_shard, device_W in zip(X_shards, y_shards, device_params)]

	for l in ls:
		l.backward()
	with torch.no_grad():
		# i代表每一层，c代表每个设备
		for i in range(len(device_params[0])):
			allreduce([device_params[c][i].grad
			for c in range(len(devices))])

	for param in device_params:
		optim.SGD(param, lr, X.shape[0])
```

简洁实现
```python
def train(net, num_gpus, batch_size, lr):
	devices = [torch.typ_gpu(i) for i in range(num_gpus)]

	def init_weights(m):
		if type(m) in [nn.Linear, nn.Conv2d]:
			nn.init.normal_(m.weight, std=0.01)

	net.apply(init_weights)
	net = nn.DataParallel(net, device_ids=devices) 
	# 将网络参数复制到各个GPU上，且之后传入数据，torch会自动将数据切分，传递给各个GPU，且之后梯度计算时，torch也会自动将各个GPU的梯度累加
	trainer = torch.optim.SGD(net.parameters(), lr)
	loss = nn.CrossEntropyLoss()
	for epoch in range(num_epochs):
		net.train()
		for X, y in train_iter:
			trainer.zero_grad()
			X, y = X.to(device[0]), y.to(device[0])
			l = loss(net(X), y)
			l.backward()
			trainer.step()
```
## 3.3 分布式训练
分布式计算不等同于之前介绍的单机多卡训练，
但本质相同，都是数据并行(data parallelism)

分布式训练中，我们通常有多台机器(worker)，每台机器有多个GPU，数据放在分布式文件系统上，而不是在机器本地的磁盘上，所有的机器都可以通过网络去分布式文件系统中读数据
分布式训练中，参数也存放在多个参数服务器中
(比如每个参数服务器存储$\frac 1 n$的模型参数)

分布式训练时，所有的机器通过网络从分布式文件系统读取数据，也通过网络和向参数服务器发送参数

在分布式训练中，GPU和GPU之间的通讯速度大于GPU和CPU之间的通讯速度大于CPU和CPU之间的通讯速度(跨机器)，因此应该尽量减少跨机器的通讯

分布式训练一个小批量样本：
首先读取数据，假设批量大小是$100$，有两台机器，每台机器有两张卡，则每台机器拿到$50$个样本，每张卡拿到$25$个样本
然后获取权重，每个GPU都完整地拿到一个模型的所有权重
然后各个GPU分别计算梯度，计算完后，先在每个机器本地做一次求和
然后每个机器把本地求和得到的梯度传回参数服务器，参数服务器更新参数
## 3.4 图像增广
### 3.4.1 图像增广介绍
在训练集尽可能收集到模型在部署时可能遇到的场景，可以有效提高模型在部署时的表现

数据增强即对一个已有的数据集进行增强(添加数据)，使得该数据集具有更好的多样性，以增强模型的泛化性
数据增强举例：
在语音数据中加入各种不同的背景噪音
改变图片的颜色和形状

一般来说，增强数据都是在线且随机生成的，即从原始数据集中选出一些数据，随机地应用一些增强方法生成新数据

对于图片来说，常见的数据增强操作有：
- 左右翻转
- 上下翻转(不一定合理，例如建筑图片上下翻转就比较不合理，树叶图片就可行)
- 切割
	从图片中随机切割出一块，然后变形到固定形状
	随机切割包括：随机选择要切割出的高宽比，随机选择要切割出的大小，随机选择要切割的位置
- 颜色调节
	改变色调、饱和度、明亮度，一般是基于当前值进行偏移
### 3.4.2 Pytorch实现
```python
# torchvision已经实现了许多转换函数
torchvision.transforms.RandomHorizontalFlip()
torchvision.transforms.RandomVerticalFlip()
torchvision.transforms.RandomResizedFlip((200, 200), scale=(0.1, 1), ratio=(0.5, 2))
torchvision.transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)
# 结合多种图像增广方式
torchvision.transforms.Compose([..., ..., ...])
```
## 3.5 微调
### 3.5.1 微调介绍
一般来说一个神经网络可以分为两个部分：除了最后一层的下面所有层是特征提取器，最后一层在提取到的特征上进行分类，即特征提取器+线性分类器

在源数据集上训练好的模型，要部署到目标数据集中，我们一般保留模型的特征提取器，丢弃线性分类器，因为要分类的标号发生了变化
之后，我们随机初始化线性分类器，在目标数据集上进一步训练，此时，模型的线性分类器部分进行重新的训练，而特征提取器部分则是在原来的基础上微调

在目标数据集上微调模型时，我们往往使用更小的学习率，以及更少的数据迭代轮数，换句话说，在目标数据集上的训练任务使用了更强的正则化，目的就是希望不要破坏原来的权重
一般来说我们希望源数据集远远复杂于目标数据集，微调的效果会比较好
(不然的话不如直接在目标数据集上训练)

有时，源数据可能也有目标数据集中的部分标号/类别，此时可以将线性分类器中该标号对应的向量/权重取出，用于初始化新的分类器，即重用部分分类器权重

我们知道神经网络通常学习有层次的特征表示，一般来说层次越高，特征和标号/类别就越相关，因此低层次的特征一般更加通用，而高层次的特征则会有更强的数据集相关性
因此，我们可以在微调时固定底部一些层的参数，使其不参与更新，这实际上让我们的模型变小了/复杂度变低了，这可以认为是一个更强的正则，如果我们的目标数据集很小，容易过拟合的话，就可以考虑这样做

总结：
微调通过使用在大数据集上预训练好的模型权重初始化要在目标数据集上训练的模型权重
预训练模型质量很重要
微调通常比从头训练一个模型速度更快、精度更高
### 3.5.2 Pytorch实现
```python
finetune_net = torchvision.models.resnet18(pretrained=True)
# 假设面向的是二分类问题
finetune_net.fc = nn.Linear(finetuen_net.fc.infeatures, 2) 
nn.init.xavier_uniform_(finetune_net.fc.weight)
```
## 3.6 